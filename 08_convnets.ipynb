{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3488f07",
   "metadata": {},
   "source": [
    "# Swissroads Project: 08 - Convulational network  \n",
    "\n",
    "## General presentation\n",
    "This is the first notebook of the Swissroad classification project. The aim of this project is to construct several classifiers to identify vehicles photographied in the streets around the Swiss School: EPFL. The project will be split into 9 jupyter notebook, each performing a specific task.\n",
    "Our dataset comprises color photographies of 6 different types of vehicles: \n",
    "* Bikes\n",
    "* Cars \n",
    "* Motorcycles\n",
    "* Trucks \n",
    "* Vans \n",
    "* Others (for example, buses, scooters, etc.) \n",
    "Our data is already split into a train, validation and test set, with respectively: 280, 139 and 50 images of sizes 250x250. \n",
    "This is a relatively small dataset. When state of the art models trained for similar tasks on larger datasets are already documented and available, a beneficial option is to use one of these pre-trained model on our own dataset, either for classification purposes directly, or as a way of extracting features from the deep layers to inject these features in other machine learning models. This option is beneficial as it allows us to benefit from information obtained on a very large dataset and allows us to save time, as training complex convolutional networks is computationally expensive and can be very time consuming especially on a personal computer. \n",
    "\n",
    "For this project, we will use the Inception_v3 model available on the tensorflow hub to extract the 2048 most important features and use them in different classifiers: \n",
    "* A k-nearest neighbors classifiers\n",
    "* A simple decision tree\n",
    "* A logistic regression model\n",
    "* Non linear classifiers such as Random Forest and SVMs \n",
    "* A dense network\n",
    "\n",
    "Finally, we will also attempt to achieve the same level of accuracy by training our own convolutional network from scratch on our specific dataset.\n",
    "\n",
    "\n",
    "## Aim of this notebook  \n",
    "\n",
    "\n",
    "In this jupyter notebook, we will work with with our raw data to train a convolutional neural network classifier on our data and evaluate if we can do as well as the Inception_v3 convNet available on the tensorflow hub. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0c3a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "# loading libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae549af8",
   "metadata": {},
   "source": [
    "As our dataset is relatively small, we will use data augmentation techniques when loading the training dataset, randomly applying rotations and color shifts to the images in the training set to increase the diversity of the training images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3872a8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create image generator\n",
    "train_generator = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "test_generator = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d33c2ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 images belonging to 6 classes.\n",
      "Found 139 images belonging to 6 classes.\n",
      "Found 50 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Train, validation and test sets\n",
    "trainset = train_generator.flow_from_directory(\n",
    "    os.path.join('swissroads', 'train'), batch_size=16, target_size=(256, 256),\n",
    "    #os.path.join('example', 'train'), batch_size=32, target_size=(224, 224),\n",
    "    shuffle=True, class_mode = 'sparse')\n",
    "validset = test_generator.flow_from_directory(\n",
    "    os.path.join('swissroads', 'valid'), batch_size=16, target_size=(256, 256),\n",
    "    #os.path.join('example', 'valid'), batch_size=32, target_size=(224, 224),\n",
    "    shuffle=False, class_mode = 'sparse')\n",
    "testset = test_generator.flow_from_directory(\n",
    "    os.path.join('swissroads', 'test'), batch_size=16, target_size=(256, 256),\n",
    "    shuffle=False, class_mode = 'sparse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651efb03",
   "metadata": {},
   "source": [
    "To design our convolutional neural network, we will take our inspiration from the VGG16 neural network. This architecture is a simple one, where we alternate convolutional layers with a 0-padding and max-pooling layers with a stride of 2.\n",
    "We chose to take inspiration from this architecture as this is a well established algorithm that is easy to understand and implement and has proven its performance on image recognation problems. \n",
    "\n",
    "The general architecture of our CNN is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3963be0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 254, 254, 10)      280       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 254, 254, 10)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 127, 10)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 20)        5020      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 62, 62, 20)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 40)        20040     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 40)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 40)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 7, 7, 40)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1960)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 11766     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 37,106\n",
      "Trainable params: 37,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "# Convolutional Network\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(filters=10, kernel_size=3, strides=1, padding = \"valid\",\n",
    "                                input_shape=(256, 256, 3)))\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2, strides = 2))\n",
    "model.add(keras.layers.Conv2D(filters=20, kernel_size=5, strides=2, padding = \"valid\"))\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2, strides = 2))\n",
    "model.add(keras.layers.Conv2D(filters=40, kernel_size=5, strides=2, padding = \"valid\"))\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2, strides = 2))\n",
    "model.add(keras.layers.Dropout(rate = 0.2))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(trainset.num_classes))\n",
    "model.add(keras.layers.Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b463ce",
   "metadata": {},
   "source": [
    "In order to achieve the best accuracy for our CNN, we will fine tune some of its hyper parameters.\n",
    "For this classifier, we will tune: \n",
    "* batch_sizehow many images are passed to the model at a time\n",
    "* drop_out rate: the percentage of activated nodes in the drop out layer\n",
    "* initialization method: the method used to initialize the weitght at each iteration; we choose between normal (random values drawn from a normal distribution), uniform (random values drawn from a uniform distribution) and zeros.  \n",
    "\n",
    "Finally, we will use the Adam optimizer as this is an adaptative optimizer that trains its learning rate during the process. \n",
    "\n",
    "In order to fight over fitting and try to save time on the computation, we will also use an early callback that will top the training when the validation_loss stops decreasing for at least 10 epochs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c07a12d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 8, 'epochs': 50, 'init_mode': 'uniform', 'rate': 0}\n",
      "Epoch 1/50\n",
      "35/35 [==============================] - 12s 334ms/step - loss: 1.7720 - acc: 0.2286 - val_loss: 1.7700 - val_acc: 0.2230\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.7507 - acc: 0.2394 - val_loss: 1.7349 - val_acc: 0.2374\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.7477 - acc: 0.2357 - val_loss: 1.7233 - val_acc: 0.2806\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.7322 - acc: 0.2822 - val_loss: 1.6780 - val_acc: 0.3525\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.6607 - acc: 0.3517 - val_loss: 1.5802 - val_acc: 0.4388\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.6321 - acc: 0.3748 - val_loss: 1.4615 - val_acc: 0.4964\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.6211 - acc: 0.3589 - val_loss: 1.4638 - val_acc: 0.4604\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.6112 - acc: 0.3659 - val_loss: 1.4547 - val_acc: 0.4532\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.5347 - acc: 0.4160 - val_loss: 1.4110 - val_acc: 0.4964\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.5534 - acc: 0.4178 - val_loss: 1.3995 - val_acc: 0.4604\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 9s 269ms/step - loss: 1.5816 - acc: 0.3841 - val_loss: 1.4263 - val_acc: 0.4388\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.5884 - acc: 0.3787 - val_loss: 1.4324 - val_acc: 0.4317\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 9s 268ms/step - loss: 1.5509 - acc: 0.4088 - val_loss: 1.3794 - val_acc: 0.4676\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.4879 - acc: 0.4499 - val_loss: 1.4097 - val_acc: 0.4748\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.5074 - acc: 0.4356 - val_loss: 1.3272 - val_acc: 0.4820\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 9s 269ms/step - loss: 1.5025 - acc: 0.4306 - val_loss: 1.2921 - val_acc: 0.5324\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.5093 - acc: 0.4284 - val_loss: 1.2361 - val_acc: 0.5827\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.4280 - acc: 0.4358 - val_loss: 1.3460 - val_acc: 0.4676\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 9s 271ms/step - loss: 1.3829 - acc: 0.4589 - val_loss: 1.1343 - val_acc: 0.6187\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 10s 283ms/step - loss: 1.3159 - acc: 0.4999 - val_loss: 1.0607 - val_acc: 0.6259\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.3330 - acc: 0.4715 - val_loss: 1.1391 - val_acc: 0.6043\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.2794 - acc: 0.5142 - val_loss: 1.0720 - val_acc: 0.6475\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.3084 - acc: 0.5053 - val_loss: 1.0434 - val_acc: 0.6331\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.2611 - acc: 0.5286 - val_loss: 1.0711 - val_acc: 0.5971\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.2998 - acc: 0.4857 - val_loss: 1.1283 - val_acc: 0.6115\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.2885 - acc: 0.5304 - val_loss: 1.0949 - val_acc: 0.5971\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.1871 - acc: 0.5408 - val_loss: 0.9579 - val_acc: 0.6475\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.2228 - acc: 0.5357 - val_loss: 1.0304 - val_acc: 0.5899\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.1734 - acc: 0.5500 - val_loss: 1.0073 - val_acc: 0.6187\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.2024 - acc: 0.5518 - val_loss: 1.0424 - val_acc: 0.5683\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.2273 - acc: 0.5123 - val_loss: 1.0575 - val_acc: 0.5971\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 9s 269ms/step - loss: 1.1232 - acc: 0.5695 - val_loss: 1.0355 - val_acc: 0.5755\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.1929 - acc: 0.5501 - val_loss: 1.0574 - val_acc: 0.5971\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 9s 271ms/step - loss: 1.1122 - acc: 0.5857 - val_loss: 1.0026 - val_acc: 0.6043\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.1159 - acc: 0.5698 - val_loss: 1.0229 - val_acc: 0.5827\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.1731 - acc: 0.5624 - val_loss: 1.0565 - val_acc: 0.5612\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.1087 - acc: 0.5751 - val_loss: 1.0688 - val_acc: 0.6187\n",
      "{'batch_size': 8, 'epochs': 50, 'init_mode': 'uniform', 'rate': 0.2}\n",
      "Epoch 1/50\n",
      "35/35 [==============================] - 10s 288ms/step - loss: 1.7674 - acc: 0.2143 - val_loss: 1.7423 - val_acc: 0.2446\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.7402 - acc: 0.2697 - val_loss: 1.6917 - val_acc: 0.3525\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7105 - acc: 0.2982 - val_loss: 1.6233 - val_acc: 0.3237\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.6501 - acc: 0.3644 - val_loss: 1.4963 - val_acc: 0.4317\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.6200 - acc: 0.3591 - val_loss: 1.4530 - val_acc: 0.4460\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.6227 - acc: 0.3589 - val_loss: 1.4595 - val_acc: 0.4604\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.5817 - acc: 0.3874 - val_loss: 1.4040 - val_acc: 0.4676\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.5568 - acc: 0.4143 - val_loss: 1.4484 - val_acc: 0.4388\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.5542 - acc: 0.3929 - val_loss: 1.3713 - val_acc: 0.4676\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.5653 - acc: 0.4142 - val_loss: 1.5232 - val_acc: 0.4676\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.5362 - acc: 0.3983 - val_loss: 1.3801 - val_acc: 0.4820\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.5354 - acc: 0.4196 - val_loss: 1.3849 - val_acc: 0.4820\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.5282 - acc: 0.4124 - val_loss: 1.3785 - val_acc: 0.4748\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.5071 - acc: 0.4160 - val_loss: 1.3747 - val_acc: 0.4748\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.4870 - acc: 0.4268 - val_loss: 1.3164 - val_acc: 0.5036\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.4609 - acc: 0.4358 - val_loss: 1.2706 - val_acc: 0.5180\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.4578 - acc: 0.4411 - val_loss: 1.2001 - val_acc: 0.5468\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.3589 - acc: 0.4839 - val_loss: 1.2270 - val_acc: 0.4676\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.3715 - acc: 0.4750 - val_loss: 1.1427 - val_acc: 0.6043\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.2753 - acc: 0.5055 - val_loss: 1.2166 - val_acc: 0.5468\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.2855 - acc: 0.5055 - val_loss: 1.0888 - val_acc: 0.5899\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.2640 - acc: 0.5195 - val_loss: 1.0832 - val_acc: 0.6115\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.3026 - acc: 0.5180 - val_loss: 1.1871 - val_acc: 0.5971\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.3152 - acc: 0.4857 - val_loss: 1.1399 - val_acc: 0.5971\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.2128 - acc: 0.5268 - val_loss: 1.2742 - val_acc: 0.4964\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.1977 - acc: 0.5322 - val_loss: 1.0388 - val_acc: 0.5899\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 9s 271ms/step - loss: 1.1655 - acc: 0.5572 - val_loss: 1.0163 - val_acc: 0.6331\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.1532 - acc: 0.5697 - val_loss: 1.0284 - val_acc: 0.6259\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.2243 - acc: 0.5341 - val_loss: 1.0057 - val_acc: 0.6331\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.1429 - acc: 0.5660 - val_loss: 1.0550 - val_acc: 0.6475\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.1491 - acc: 0.5803 - val_loss: 1.0140 - val_acc: 0.6331\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.1619 - acc: 0.5392 - val_loss: 1.0456 - val_acc: 0.6115\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.1169 - acc: 0.5768 - val_loss: 1.1740 - val_acc: 0.5971\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.0817 - acc: 0.5947 - val_loss: 1.0011 - val_acc: 0.6331\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.0282 - acc: 0.6036 - val_loss: 1.0431 - val_acc: 0.6619\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.0731 - acc: 0.5999 - val_loss: 1.0369 - val_acc: 0.6043\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.1191 - acc: 0.5750 - val_loss: 1.0052 - val_acc: 0.6115\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.0243 - acc: 0.6160 - val_loss: 1.0003 - val_acc: 0.6475\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 10s 281ms/step - loss: 1.0062 - acc: 0.6054 - val_loss: 1.0486 - val_acc: 0.6043\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 10s 283ms/step - loss: 0.9897 - acc: 0.6196 - val_loss: 0.9855 - val_acc: 0.6547\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.0173 - acc: 0.5966 - val_loss: 0.9835 - val_acc: 0.6403\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 10s 281ms/step - loss: 1.0186 - acc: 0.6108 - val_loss: 1.0096 - val_acc: 0.6331\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 0.9512 - acc: 0.6483 - val_loss: 1.0105 - val_acc: 0.6331\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 0.9662 - acc: 0.6607 - val_loss: 0.9896 - val_acc: 0.6259\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 9s 270ms/step - loss: 0.9726 - acc: 0.6322 - val_loss: 1.0708 - val_acc: 0.6043\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 0.9892 - acc: 0.6231 - val_loss: 0.9990 - val_acc: 0.6259\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 9s 268ms/step - loss: 0.9105 - acc: 0.6625 - val_loss: 1.0377 - val_acc: 0.6691\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 0.9685 - acc: 0.6429 - val_loss: 1.0171 - val_acc: 0.6403\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 0.9394 - acc: 0.6642 - val_loss: 1.0582 - val_acc: 0.6187\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 0.9524 - acc: 0.6286 - val_loss: 1.0070 - val_acc: 0.6331\n",
      "{'batch_size': 8, 'epochs': 50, 'init_mode': 'uniform', 'rate': 0.5}\n",
      "Epoch 1/50\n",
      "35/35 [==============================] - 10s 286ms/step - loss: 1.7601 - acc: 0.2392 - val_loss: 1.7406 - val_acc: 0.2374\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.7521 - acc: 0.2339 - val_loss: 1.7339 - val_acc: 0.2734\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 10s 283ms/step - loss: 1.7429 - acc: 0.2410 - val_loss: 1.7255 - val_acc: 0.2446\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.7433 - acc: 0.2804 - val_loss: 1.7086 - val_acc: 0.3237\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.6755 - acc: 0.3428 - val_loss: 1.5779 - val_acc: 0.3885\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.6375 - acc: 0.3749 - val_loss: 1.4783 - val_acc: 0.4388\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.6635 - acc: 0.3429 - val_loss: 1.4827 - val_acc: 0.4604\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.5946 - acc: 0.3696 - val_loss: 1.4453 - val_acc: 0.4676\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.6241 - acc: 0.3570 - val_loss: 1.4598 - val_acc: 0.4676\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.6260 - acc: 0.3678 - val_loss: 1.4548 - val_acc: 0.4604\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.5613 - acc: 0.3874 - val_loss: 1.4393 - val_acc: 0.4245\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 9s 270ms/step - loss: 1.5627 - acc: 0.4107 - val_loss: 1.4335 - val_acc: 0.4173\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.5596 - acc: 0.3891 - val_loss: 1.4210 - val_acc: 0.4101\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.5653 - acc: 0.3965 - val_loss: 1.4020 - val_acc: 0.4245\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.5571 - acc: 0.3858 - val_loss: 1.4021 - val_acc: 0.4964\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.5407 - acc: 0.4124 - val_loss: 1.4116 - val_acc: 0.4245\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.5573 - acc: 0.4107 - val_loss: 1.3793 - val_acc: 0.4460\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.5081 - acc: 0.4125 - val_loss: 1.3485 - val_acc: 0.4317\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.5112 - acc: 0.4447 - val_loss: 1.3679 - val_acc: 0.4820\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.4750 - acc: 0.4144 - val_loss: 1.3433 - val_acc: 0.5180\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.4435 - acc: 0.4483 - val_loss: 1.3151 - val_acc: 0.4964\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 10s 281ms/step - loss: 1.4641 - acc: 0.4320 - val_loss: 1.2999 - val_acc: 0.4964\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.4183 - acc: 0.4679 - val_loss: 1.3166 - val_acc: 0.4892\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.4175 - acc: 0.4641 - val_loss: 1.3084 - val_acc: 0.5252\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.3916 - acc: 0.4589 - val_loss: 1.3642 - val_acc: 0.5036\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.4092 - acc: 0.4643 - val_loss: 1.2934 - val_acc: 0.5180\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.4120 - acc: 0.4678 - val_loss: 1.3201 - val_acc: 0.5540\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.3616 - acc: 0.4839 - val_loss: 1.3094 - val_acc: 0.5468\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 9s 270ms/step - loss: 1.3047 - acc: 0.4982 - val_loss: 1.2675 - val_acc: 0.5180\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.3592 - acc: 0.4840 - val_loss: 1.3057 - val_acc: 0.5252\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.2786 - acc: 0.5340 - val_loss: 1.1649 - val_acc: 0.6043\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 9s 270ms/step - loss: 1.3112 - acc: 0.4982 - val_loss: 1.1630 - val_acc: 0.5468\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.2784 - acc: 0.4982 - val_loss: 1.1425 - val_acc: 0.5971\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 9s 270ms/step - loss: 1.2175 - acc: 0.5142 - val_loss: 1.1696 - val_acc: 0.5755\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.2571 - acc: 0.5053 - val_loss: 1.1029 - val_acc: 0.6043\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.2139 - acc: 0.5359 - val_loss: 1.0992 - val_acc: 0.5827\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.1943 - acc: 0.5287 - val_loss: 1.1055 - val_acc: 0.6043\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 10s 283ms/step - loss: 1.2184 - acc: 0.5180 - val_loss: 1.0703 - val_acc: 0.6115\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.1954 - acc: 0.5375 - val_loss: 1.0599 - val_acc: 0.6187\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.1828 - acc: 0.5359 - val_loss: 1.0716 - val_acc: 0.5971\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.1644 - acc: 0.5394 - val_loss: 1.0579 - val_acc: 0.6259\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.2025 - acc: 0.5481 - val_loss: 1.0617 - val_acc: 0.5899\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.1695 - acc: 0.5535 - val_loss: 1.0164 - val_acc: 0.6403\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.1909 - acc: 0.5323 - val_loss: 1.0597 - val_acc: 0.6331\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.1591 - acc: 0.5910 - val_loss: 1.0419 - val_acc: 0.6043\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.0903 - acc: 0.5733 - val_loss: 1.0266 - val_acc: 0.6187\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.0502 - acc: 0.6000 - val_loss: 1.0836 - val_acc: 0.6115\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.1506 - acc: 0.5499 - val_loss: 1.0722 - val_acc: 0.6331\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 9s 271ms/step - loss: 1.0530 - acc: 0.6071 - val_loss: 1.0558 - val_acc: 0.6403\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.0876 - acc: 0.5875 - val_loss: 1.0569 - val_acc: 0.6043\n",
      "{'batch_size': 8, 'epochs': 50, 'init_mode': 'normal', 'rate': 0}\n",
      "Epoch 1/50\n",
      "35/35 [==============================] - 10s 286ms/step - loss: 1.7654 - acc: 0.2250 - val_loss: 1.7274 - val_acc: 0.3237\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 10s 285ms/step - loss: 1.7134 - acc: 0.2823 - val_loss: 1.6488 - val_acc: 0.3597\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.6348 - acc: 0.3517 - val_loss: 1.4714 - val_acc: 0.4604\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.5874 - acc: 0.3715 - val_loss: 1.4434 - val_acc: 0.4532\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 10s 283ms/step - loss: 1.5647 - acc: 0.3930 - val_loss: 1.4138 - val_acc: 0.4964\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.5321 - acc: 0.4124 - val_loss: 1.3896 - val_acc: 0.5108\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.4913 - acc: 0.4198 - val_loss: 1.3376 - val_acc: 0.5540\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.4596 - acc: 0.4500 - val_loss: 1.3206 - val_acc: 0.5180\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.4100 - acc: 0.4643 - val_loss: 1.2642 - val_acc: 0.5180\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 9s 270ms/step - loss: 1.4109 - acc: 0.4874 - val_loss: 1.2110 - val_acc: 0.5755\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.3306 - acc: 0.5123 - val_loss: 1.1827 - val_acc: 0.5612\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 9s 271ms/step - loss: 1.3121 - acc: 0.4855 - val_loss: 1.1017 - val_acc: 0.6043\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.2562 - acc: 0.5393 - val_loss: 1.0747 - val_acc: 0.5827\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.2348 - acc: 0.5392 - val_loss: 1.0669 - val_acc: 0.5899\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.2846 - acc: 0.5197 - val_loss: 1.0308 - val_acc: 0.6115\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.2124 - acc: 0.5214 - val_loss: 1.0742 - val_acc: 0.5540\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.1514 - acc: 0.5716 - val_loss: 0.9676 - val_acc: 0.6331\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.1806 - acc: 0.5411 - val_loss: 0.9650 - val_acc: 0.6403\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.1785 - acc: 0.5321 - val_loss: 0.9721 - val_acc: 0.6547\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 10s 283ms/step - loss: 1.0949 - acc: 0.5892 - val_loss: 0.9210 - val_acc: 0.6691\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.1104 - acc: 0.5821 - val_loss: 0.9864 - val_acc: 0.6619\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.0768 - acc: 0.5982 - val_loss: 0.9288 - val_acc: 0.6906\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.1208 - acc: 0.5715 - val_loss: 0.9229 - val_acc: 0.6475\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.0036 - acc: 0.6338 - val_loss: 0.9468 - val_acc: 0.6331\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.1084 - acc: 0.5752 - val_loss: 0.9325 - val_acc: 0.6115\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.0107 - acc: 0.6107 - val_loss: 0.9340 - val_acc: 0.6403\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 9s 270ms/step - loss: 0.9668 - acc: 0.6411 - val_loss: 0.9581 - val_acc: 0.6619\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.0017 - acc: 0.6268 - val_loss: 0.9599 - val_acc: 0.6331\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 9s 269ms/step - loss: 1.0160 - acc: 0.5966 - val_loss: 0.9165 - val_acc: 0.6403\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 0.9955 - acc: 0.6287 - val_loss: 1.0260 - val_acc: 0.5899\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 0.9380 - acc: 0.6321 - val_loss: 0.9662 - val_acc: 0.6835\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 0.9386 - acc: 0.6480 - val_loss: 1.0223 - val_acc: 0.5971\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 0.9197 - acc: 0.6660 - val_loss: 0.9561 - val_acc: 0.6331\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 0.8921 - acc: 0.6625 - val_loss: 1.1262 - val_acc: 0.5683\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 0.9277 - acc: 0.6732 - val_loss: 0.9430 - val_acc: 0.6187\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 0.8447 - acc: 0.6805 - val_loss: 0.9239 - val_acc: 0.6475\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 0.8886 - acc: 0.6518 - val_loss: 1.0124 - val_acc: 0.6403\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 10s 286ms/step - loss: 0.8349 - acc: 0.7197 - val_loss: 1.0547 - val_acc: 0.5827\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 10s 281ms/step - loss: 0.8493 - acc: 0.6732 - val_loss: 0.9999 - val_acc: 0.6331\n",
      "{'batch_size': 8, 'epochs': 50, 'init_mode': 'normal', 'rate': 0.2}\n",
      "Epoch 1/50\n",
      "35/35 [==============================] - 10s 290ms/step - loss: 1.7617 - acc: 0.2196 - val_loss: 1.7271 - val_acc: 0.2662\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 10s 285ms/step - loss: 1.7448 - acc: 0.2751 - val_loss: 1.7161 - val_acc: 0.3453\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7252 - acc: 0.2946 - val_loss: 1.6533 - val_acc: 0.3525\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 10s 281ms/step - loss: 1.6620 - acc: 0.3409 - val_loss: 1.5678 - val_acc: 0.4460\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.6206 - acc: 0.3680 - val_loss: 1.4946 - val_acc: 0.4676\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.5812 - acc: 0.3749 - val_loss: 1.4009 - val_acc: 0.4964\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.5696 - acc: 0.3893 - val_loss: 1.4232 - val_acc: 0.4820\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.4770 - acc: 0.4178 - val_loss: 1.2445 - val_acc: 0.5468\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.4541 - acc: 0.4376 - val_loss: 1.2597 - val_acc: 0.5396\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.3673 - acc: 0.4803 - val_loss: 1.1922 - val_acc: 0.5468\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 9s 271ms/step - loss: 1.3894 - acc: 0.4698 - val_loss: 1.1701 - val_acc: 0.5540\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.3491 - acc: 0.4982 - val_loss: 1.2751 - val_acc: 0.5827\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 9s 271ms/step - loss: 1.3386 - acc: 0.4804 - val_loss: 1.1226 - val_acc: 0.5612\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.2570 - acc: 0.4912 - val_loss: 1.0993 - val_acc: 0.5540\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 10s 283ms/step - loss: 1.2787 - acc: 0.5393 - val_loss: 1.1452 - val_acc: 0.5683\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.2080 - acc: 0.5411 - val_loss: 1.0672 - val_acc: 0.6115\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.2356 - acc: 0.5179 - val_loss: 1.0617 - val_acc: 0.5612\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.2075 - acc: 0.5304 - val_loss: 1.0702 - val_acc: 0.5971\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.2007 - acc: 0.5411 - val_loss: 1.0490 - val_acc: 0.6187\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 10s 283ms/step - loss: 1.2118 - acc: 0.5320 - val_loss: 1.0713 - val_acc: 0.5899\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.1710 - acc: 0.5373 - val_loss: 1.1036 - val_acc: 0.5827\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 10s 281ms/step - loss: 1.2162 - acc: 0.5358 - val_loss: 1.2142 - val_acc: 0.5396\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 10s 285ms/step - loss: 1.1141 - acc: 0.5911 - val_loss: 1.0468 - val_acc: 0.6475\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.1395 - acc: 0.5661 - val_loss: 1.0409 - val_acc: 0.6187\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.1391 - acc: 0.5839 - val_loss: 1.0057 - val_acc: 0.6403\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.1897 - acc: 0.5554 - val_loss: 1.0219 - val_acc: 0.6331\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.0746 - acc: 0.5856 - val_loss: 1.0370 - val_acc: 0.6259\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.0382 - acc: 0.6212 - val_loss: 0.9990 - val_acc: 0.6331\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.0589 - acc: 0.6142 - val_loss: 1.0249 - val_acc: 0.5827\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.0140 - acc: 0.6161 - val_loss: 1.0115 - val_acc: 0.6187\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.0686 - acc: 0.5928 - val_loss: 1.0449 - val_acc: 0.6187\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.0597 - acc: 0.5839 - val_loss: 1.0342 - val_acc: 0.6115\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.0427 - acc: 0.6001 - val_loss: 0.9900 - val_acc: 0.6906\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.0408 - acc: 0.5999 - val_loss: 1.0223 - val_acc: 0.6115\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 0.9977 - acc: 0.6144 - val_loss: 0.9922 - val_acc: 0.6187\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 0.9944 - acc: 0.6214 - val_loss: 0.9799 - val_acc: 0.6475\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.0108 - acc: 0.6304 - val_loss: 1.1485 - val_acc: 0.6115\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 10s 287ms/step - loss: 0.9515 - acc: 0.6625 - val_loss: 0.9817 - val_acc: 0.6547\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 0.9404 - acc: 0.6660 - val_loss: 1.0069 - val_acc: 0.6331\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 10s 287ms/step - loss: 0.9110 - acc: 0.6750 - val_loss: 0.9633 - val_acc: 0.6691\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 10s 281ms/step - loss: 0.9030 - acc: 0.6535 - val_loss: 1.0130 - val_acc: 0.6403\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.0113 - acc: 0.6412 - val_loss: 1.0916 - val_acc: 0.5899\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 0.8991 - acc: 0.6749 - val_loss: 1.0254 - val_acc: 0.6547\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 0.9114 - acc: 0.6500 - val_loss: 1.0284 - val_acc: 0.6259\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 0.8790 - acc: 0.6856 - val_loss: 1.0084 - val_acc: 0.6547\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 0.8482 - acc: 0.6661 - val_loss: 1.0291 - val_acc: 0.6547\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 0.8274 - acc: 0.7053 - val_loss: 1.0569 - val_acc: 0.6475\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 9s 271ms/step - loss: 0.8307 - acc: 0.6944 - val_loss: 1.1141 - val_acc: 0.6259\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 0.8493 - acc: 0.6911 - val_loss: 1.0453 - val_acc: 0.6115\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 0.8399 - acc: 0.6929 - val_loss: 1.0181 - val_acc: 0.6331\n",
      "{'batch_size': 8, 'epochs': 50, 'init_mode': 'normal', 'rate': 0.5}\n",
      "Epoch 1/50\n",
      "35/35 [==============================] - 10s 293ms/step - loss: 1.7693 - acc: 0.2036 - val_loss: 1.7334 - val_acc: 0.2374\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 10s 288ms/step - loss: 1.7509 - acc: 0.2446 - val_loss: 1.7302 - val_acc: 0.2446\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 10s 285ms/step - loss: 1.7380 - acc: 0.2661 - val_loss: 1.7083 - val_acc: 0.2950\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 10s 281ms/step - loss: 1.7148 - acc: 0.2944 - val_loss: 1.6062 - val_acc: 0.3885\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.6152 - acc: 0.3430 - val_loss: 1.4502 - val_acc: 0.4604\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 10s 281ms/step - loss: 1.6192 - acc: 0.3767 - val_loss: 1.4222 - val_acc: 0.4101\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 9s 271ms/step - loss: 1.5849 - acc: 0.3838 - val_loss: 1.3757 - val_acc: 0.4173\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.5621 - acc: 0.3822 - val_loss: 1.4341 - val_acc: 0.5252\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.4882 - acc: 0.4411 - val_loss: 1.3144 - val_acc: 0.4604\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.5034 - acc: 0.4018 - val_loss: 1.3176 - val_acc: 0.5036\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.4739 - acc: 0.4251 - val_loss: 1.2189 - val_acc: 0.5396\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.4120 - acc: 0.4464 - val_loss: 1.1881 - val_acc: 0.5612\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.4247 - acc: 0.4341 - val_loss: 1.1790 - val_acc: 0.5468\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.3704 - acc: 0.4554 - val_loss: 1.1703 - val_acc: 0.5683\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.3205 - acc: 0.4875 - val_loss: 1.0898 - val_acc: 0.5827\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.3232 - acc: 0.4963 - val_loss: 1.1076 - val_acc: 0.5827\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.3128 - acc: 0.4821 - val_loss: 1.0689 - val_acc: 0.6043\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.2658 - acc: 0.5088 - val_loss: 1.1057 - val_acc: 0.5540\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.2695 - acc: 0.5018 - val_loss: 1.0689 - val_acc: 0.6331\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.2057 - acc: 0.5217 - val_loss: 1.0259 - val_acc: 0.5971\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 10s 281ms/step - loss: 1.2884 - acc: 0.4840 - val_loss: 1.0912 - val_acc: 0.5899\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 10s 285ms/step - loss: 1.2183 - acc: 0.5250 - val_loss: 1.2081 - val_acc: 0.5396\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.2403 - acc: 0.5143 - val_loss: 1.0758 - val_acc: 0.5683\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.2114 - acc: 0.5054 - val_loss: 1.0686 - val_acc: 0.6115\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.1582 - acc: 0.5322 - val_loss: 1.0125 - val_acc: 0.6115\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.0940 - acc: 0.5644 - val_loss: 1.1176 - val_acc: 0.5899\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.2619 - acc: 0.5250 - val_loss: 1.0672 - val_acc: 0.5971\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.1748 - acc: 0.5358 - val_loss: 1.1208 - val_acc: 0.5755\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.1634 - acc: 0.5678 - val_loss: 1.0422 - val_acc: 0.6187\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.1710 - acc: 0.5394 - val_loss: 1.0705 - val_acc: 0.5899\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.1656 - acc: 0.5536 - val_loss: 1.0806 - val_acc: 0.6403\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.1504 - acc: 0.5465 - val_loss: 1.0186 - val_acc: 0.6475\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.0641 - acc: 0.5770 - val_loss: 1.0550 - val_acc: 0.6187\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.1858 - acc: 0.5321 - val_loss: 1.0595 - val_acc: 0.5899\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 9s 271ms/step - loss: 1.1258 - acc: 0.5395 - val_loss: 1.0732 - val_acc: 0.6691\n",
      "{'batch_size': 8, 'epochs': 50, 'init_mode': 'zero', 'rate': 0}\n",
      "Epoch 1/50\n",
      "35/35 [==============================] - 10s 291ms/step - loss: 1.7891 - acc: 0.2232 - val_loss: 1.7863 - val_acc: 0.2302\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.7844 - acc: 0.2304 - val_loss: 1.7811 - val_acc: 0.2374\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 10s 281ms/step - loss: 1.7786 - acc: 0.2374 - val_loss: 1.7765 - val_acc: 0.2374\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.7745 - acc: 0.2375 - val_loss: 1.7722 - val_acc: 0.2374\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 10s 285ms/step - loss: 1.7703 - acc: 0.2411 - val_loss: 1.7684 - val_acc: 0.2374\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.7684 - acc: 0.2287 - val_loss: 1.7653 - val_acc: 0.2374\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.7687 - acc: 0.2303 - val_loss: 1.7626 - val_acc: 0.2374\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7581 - acc: 0.2358 - val_loss: 1.7597 - val_acc: 0.2374\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.7592 - acc: 0.2322 - val_loss: 1.7572 - val_acc: 0.2374\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.7560 - acc: 0.2517 - val_loss: 1.7549 - val_acc: 0.2374\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.7572 - acc: 0.2232 - val_loss: 1.7530 - val_acc: 0.2374\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.7558 - acc: 0.2465 - val_loss: 1.7513 - val_acc: 0.2374\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.7507 - acc: 0.2250 - val_loss: 1.7497 - val_acc: 0.2374\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.7466 - acc: 0.2465 - val_loss: 1.7481 - val_acc: 0.2374\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7514 - acc: 0.2232 - val_loss: 1.7468 - val_acc: 0.2374\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.7471 - acc: 0.2322 - val_loss: 1.7457 - val_acc: 0.2374\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.7487 - acc: 0.2410 - val_loss: 1.7445 - val_acc: 0.2374\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.7431 - acc: 0.2375 - val_loss: 1.7435 - val_acc: 0.2374\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 9s 271ms/step - loss: 1.7426 - acc: 0.2392 - val_loss: 1.7426 - val_acc: 0.2374\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 10s 285ms/step - loss: 1.7457 - acc: 0.2357 - val_loss: 1.7417 - val_acc: 0.2374\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.7437 - acc: 0.2180 - val_loss: 1.7410 - val_acc: 0.2374\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.7386 - acc: 0.2447 - val_loss: 1.7403 - val_acc: 0.2374\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.7400 - acc: 0.2428 - val_loss: 1.7397 - val_acc: 0.2374\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.7443 - acc: 0.2269 - val_loss: 1.7392 - val_acc: 0.2374\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.7437 - acc: 0.2355 - val_loss: 1.7388 - val_acc: 0.2374\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7395 - acc: 0.2428 - val_loss: 1.7384 - val_acc: 0.2374\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.7381 - acc: 0.2428 - val_loss: 1.7380 - val_acc: 0.2374\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 9s 271ms/step - loss: 1.7282 - acc: 0.2340 - val_loss: 1.7375 - val_acc: 0.2374\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.7511 - acc: 0.2357 - val_loss: 1.7373 - val_acc: 0.2374\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.7319 - acc: 0.2463 - val_loss: 1.7369 - val_acc: 0.2374\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.7373 - acc: 0.2286 - val_loss: 1.7367 - val_acc: 0.2374\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.7421 - acc: 0.2340 - val_loss: 1.7364 - val_acc: 0.2374\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.7288 - acc: 0.2501 - val_loss: 1.7362 - val_acc: 0.2374\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.7470 - acc: 0.2232 - val_loss: 1.7361 - val_acc: 0.2374\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.7360 - acc: 0.2321 - val_loss: 1.7359 - val_acc: 0.2374\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.7422 - acc: 0.2340 - val_loss: 1.7357 - val_acc: 0.2374\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.7394 - acc: 0.2322 - val_loss: 1.7356 - val_acc: 0.2374\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.7322 - acc: 0.2357 - val_loss: 1.7354 - val_acc: 0.2374\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 10s 281ms/step - loss: 1.7457 - acc: 0.2304 - val_loss: 1.7353 - val_acc: 0.2374\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.7351 - acc: 0.2393 - val_loss: 1.7352 - val_acc: 0.2374\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.7367 - acc: 0.2268 - val_loss: 1.7351 - val_acc: 0.2374\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.7312 - acc: 0.2447 - val_loss: 1.7350 - val_acc: 0.2374\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7449 - acc: 0.2358 - val_loss: 1.7349 - val_acc: 0.2374\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 9s 271ms/step - loss: 1.7299 - acc: 0.2180 - val_loss: 1.7349 - val_acc: 0.2374\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.7460 - acc: 0.2411 - val_loss: 1.7348 - val_acc: 0.2374\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.7317 - acc: 0.2535 - val_loss: 1.7347 - val_acc: 0.2374\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.7311 - acc: 0.2214 - val_loss: 1.7346 - val_acc: 0.2374\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.7309 - acc: 0.2501 - val_loss: 1.7346 - val_acc: 0.2374\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.7474 - acc: 0.2196 - val_loss: 1.7346 - val_acc: 0.2374\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.7378 - acc: 0.2482 - val_loss: 1.7345 - val_acc: 0.2374\n",
      "{'batch_size': 8, 'epochs': 50, 'init_mode': 'zero', 'rate': 0.2}\n",
      "Epoch 1/50\n",
      "35/35 [==============================] - 10s 296ms/step - loss: 1.7890 - acc: 0.2215 - val_loss: 1.7861 - val_acc: 0.2374\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 10s 283ms/step - loss: 1.7838 - acc: 0.2322 - val_loss: 1.7809 - val_acc: 0.2374\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.7798 - acc: 0.2391 - val_loss: 1.7766 - val_acc: 0.2374\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 10s 287ms/step - loss: 1.7739 - acc: 0.2410 - val_loss: 1.7722 - val_acc: 0.2374\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7712 - acc: 0.2305 - val_loss: 1.7685 - val_acc: 0.2374\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.7665 - acc: 0.2426 - val_loss: 1.7650 - val_acc: 0.2374\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.7635 - acc: 0.2268 - val_loss: 1.7619 - val_acc: 0.2374\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.7599 - acc: 0.2517 - val_loss: 1.7591 - val_acc: 0.2374\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.7577 - acc: 0.2303 - val_loss: 1.7566 - val_acc: 0.2374\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7587 - acc: 0.2429 - val_loss: 1.7544 - val_acc: 0.2374\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 9s 270ms/step - loss: 1.7586 - acc: 0.2162 - val_loss: 1.7527 - val_acc: 0.2374\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.7488 - acc: 0.2466 - val_loss: 1.7508 - val_acc: 0.2374\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.7499 - acc: 0.2338 - val_loss: 1.7490 - val_acc: 0.2374\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7466 - acc: 0.2447 - val_loss: 1.7476 - val_acc: 0.2374\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.7510 - acc: 0.2303 - val_loss: 1.7462 - val_acc: 0.2374\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.7465 - acc: 0.2339 - val_loss: 1.7451 - val_acc: 0.2374\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.7473 - acc: 0.2357 - val_loss: 1.7440 - val_acc: 0.2374\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.7437 - acc: 0.2375 - val_loss: 1.7431 - val_acc: 0.2374\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.7488 - acc: 0.2305 - val_loss: 1.7422 - val_acc: 0.2374\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.7433 - acc: 0.2304 - val_loss: 1.7416 - val_acc: 0.2374\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 10s 283ms/step - loss: 1.7425 - acc: 0.2446 - val_loss: 1.7409 - val_acc: 0.2374\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.7505 - acc: 0.2251 - val_loss: 1.7404 - val_acc: 0.2374\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7306 - acc: 0.2517 - val_loss: 1.7396 - val_acc: 0.2374\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.7441 - acc: 0.2233 - val_loss: 1.7391 - val_acc: 0.2374\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 10s 281ms/step - loss: 1.7446 - acc: 0.2287 - val_loss: 1.7387 - val_acc: 0.2374\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 9s 270ms/step - loss: 1.7358 - acc: 0.2393 - val_loss: 1.7382 - val_acc: 0.2374\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7449 - acc: 0.2357 - val_loss: 1.7379 - val_acc: 0.2374\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.7304 - acc: 0.2446 - val_loss: 1.7374 - val_acc: 0.2374\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.7436 - acc: 0.2268 - val_loss: 1.7371 - val_acc: 0.2374\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.7382 - acc: 0.2322 - val_loss: 1.7369 - val_acc: 0.2374\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.7451 - acc: 0.2374 - val_loss: 1.7366 - val_acc: 0.2374\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 9s 271ms/step - loss: 1.7351 - acc: 0.2357 - val_loss: 1.7364 - val_acc: 0.2374\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7290 - acc: 0.2412 - val_loss: 1.7361 - val_acc: 0.2374\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7442 - acc: 0.2322 - val_loss: 1.7360 - val_acc: 0.2374\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 9s 271ms/step - loss: 1.7381 - acc: 0.2321 - val_loss: 1.7358 - val_acc: 0.2374\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.7362 - acc: 0.2375 - val_loss: 1.7356 - val_acc: 0.2374\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7375 - acc: 0.2340 - val_loss: 1.7355 - val_acc: 0.2374\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 10s 285ms/step - loss: 1.7397 - acc: 0.2357 - val_loss: 1.7354 - val_acc: 0.2374\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.7351 - acc: 0.2287 - val_loss: 1.7353 - val_acc: 0.2374\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.7497 - acc: 0.2287 - val_loss: 1.7352 - val_acc: 0.2374\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 10s 283ms/step - loss: 1.7371 - acc: 0.2394 - val_loss: 1.7351 - val_acc: 0.2374\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.7324 - acc: 0.2288 - val_loss: 1.7351 - val_acc: 0.2374\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.7429 - acc: 0.2445 - val_loss: 1.7350 - val_acc: 0.2374\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.7421 - acc: 0.2250 - val_loss: 1.7349 - val_acc: 0.2374\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.7274 - acc: 0.2465 - val_loss: 1.7348 - val_acc: 0.2374\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 9s 271ms/step - loss: 1.7461 - acc: 0.2252 - val_loss: 1.7348 - val_acc: 0.2374\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.7385 - acc: 0.2161 - val_loss: 1.7347 - val_acc: 0.2374\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7328 - acc: 0.2411 - val_loss: 1.7347 - val_acc: 0.2374\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 10s 281ms/step - loss: 1.7417 - acc: 0.2464 - val_loss: 1.7346 - val_acc: 0.2374\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.7336 - acc: 0.2268 - val_loss: 1.7346 - val_acc: 0.2374\n",
      "{'batch_size': 8, 'epochs': 50, 'init_mode': 'zero', 'rate': 0.5}\n",
      "Epoch 1/50\n",
      "35/35 [==============================] - 10s 292ms/step - loss: 1.7893 - acc: 0.2357 - val_loss: 1.7863 - val_acc: 0.2374\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 10s 283ms/step - loss: 1.7846 - acc: 0.2287 - val_loss: 1.7816 - val_acc: 0.2374\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.7802 - acc: 0.2340 - val_loss: 1.7773 - val_acc: 0.2374\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 10s 284ms/step - loss: 1.7752 - acc: 0.2358 - val_loss: 1.7733 - val_acc: 0.2374\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.7717 - acc: 0.2375 - val_loss: 1.7695 - val_acc: 0.2374\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 10s 281ms/step - loss: 1.7696 - acc: 0.2358 - val_loss: 1.7664 - val_acc: 0.2374\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 10s 281ms/step - loss: 1.7662 - acc: 0.2268 - val_loss: 1.7634 - val_acc: 0.2374\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.7625 - acc: 0.2321 - val_loss: 1.7604 - val_acc: 0.2374\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.7605 - acc: 0.2483 - val_loss: 1.7580 - val_acc: 0.2374\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 9s 271ms/step - loss: 1.7584 - acc: 0.2250 - val_loss: 1.7557 - val_acc: 0.2374\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.7537 - acc: 0.2394 - val_loss: 1.7536 - val_acc: 0.2374\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.7527 - acc: 0.2321 - val_loss: 1.7516 - val_acc: 0.2374\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.7546 - acc: 0.2357 - val_loss: 1.7499 - val_acc: 0.2374\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.7430 - acc: 0.2536 - val_loss: 1.7482 - val_acc: 0.2374\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.7552 - acc: 0.2178 - val_loss: 1.7470 - val_acc: 0.2374\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.7501 - acc: 0.2340 - val_loss: 1.7458 - val_acc: 0.2374\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.7427 - acc: 0.2411 - val_loss: 1.7447 - val_acc: 0.2374\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.7455 - acc: 0.2304 - val_loss: 1.7436 - val_acc: 0.2374\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 9s 269ms/step - loss: 1.7423 - acc: 0.2392 - val_loss: 1.7427 - val_acc: 0.2374\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 10s 283ms/step - loss: 1.7443 - acc: 0.2357 - val_loss: 1.7418 - val_acc: 0.2374\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.7370 - acc: 0.2357 - val_loss: 1.7410 - val_acc: 0.2374\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 10s 281ms/step - loss: 1.7464 - acc: 0.2340 - val_loss: 1.7404 - val_acc: 0.2374\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.7319 - acc: 0.2394 - val_loss: 1.7397 - val_acc: 0.2374\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.7504 - acc: 0.2303 - val_loss: 1.7393 - val_acc: 0.2374\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.7368 - acc: 0.2428 - val_loss: 1.7387 - val_acc: 0.2374\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7522 - acc: 0.2410 - val_loss: 1.7384 - val_acc: 0.2374\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.7330 - acc: 0.2268 - val_loss: 1.7379 - val_acc: 0.2374\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.7435 - acc: 0.2341 - val_loss: 1.7376 - val_acc: 0.2374\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.7423 - acc: 0.2304 - val_loss: 1.7373 - val_acc: 0.2374\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.7378 - acc: 0.2304 - val_loss: 1.7370 - val_acc: 0.2374\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 9s 270ms/step - loss: 1.7307 - acc: 0.2411 - val_loss: 1.7367 - val_acc: 0.2374\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7470 - acc: 0.2286 - val_loss: 1.7365 - val_acc: 0.2374\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.7278 - acc: 0.2428 - val_loss: 1.7362 - val_acc: 0.2374\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7421 - acc: 0.2374 - val_loss: 1.7360 - val_acc: 0.2374\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.7333 - acc: 0.2340 - val_loss: 1.7358 - val_acc: 0.2374\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.7393 - acc: 0.2393 - val_loss: 1.7357 - val_acc: 0.2374\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.7400 - acc: 0.2304 - val_loss: 1.7355 - val_acc: 0.2374\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 10s 283ms/step - loss: 1.7396 - acc: 0.2358 - val_loss: 1.7355 - val_acc: 0.2374\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 10s 281ms/step - loss: 1.7317 - acc: 0.2392 - val_loss: 1.7353 - val_acc: 0.2374\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.7383 - acc: 0.2428 - val_loss: 1.7352 - val_acc: 0.2374\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 10s 285ms/step - loss: 1.7461 - acc: 0.2178 - val_loss: 1.7351 - val_acc: 0.2374\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.7275 - acc: 0.2464 - val_loss: 1.7350 - val_acc: 0.2374\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.7449 - acc: 0.2358 - val_loss: 1.7349 - val_acc: 0.2374\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.7328 - acc: 0.2463 - val_loss: 1.7349 - val_acc: 0.2374\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.7382 - acc: 0.2339 - val_loss: 1.7348 - val_acc: 0.2374\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.7380 - acc: 0.2374 - val_loss: 1.7347 - val_acc: 0.2374\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.7373 - acc: 0.2375 - val_loss: 1.7347 - val_acc: 0.2374\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 9s 267ms/step - loss: 1.7407 - acc: 0.2197 - val_loss: 1.7347 - val_acc: 0.2374\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.7411 - acc: 0.2358 - val_loss: 1.7346 - val_acc: 0.2374\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 9s 269ms/step - loss: 1.7369 - acc: 0.2446 - val_loss: 1.7346 - val_acc: 0.2374\n",
      "{'batch_size': 16, 'epochs': 50, 'init_mode': 'uniform', 'rate': 0}\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 5s 316ms/step - loss: 1.7850 - acc: 0.1800 - val_loss: 1.7511 - val_acc: 0.2302\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 5s 306ms/step - loss: 1.7557 - acc: 0.2207 - val_loss: 1.7404 - val_acc: 0.2374\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 5s 305ms/step - loss: 1.7489 - acc: 0.2318 - val_loss: 1.7350 - val_acc: 0.2374\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 1.7520 - acc: 0.2207 - val_loss: 1.7256 - val_acc: 0.2662\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 1.7182 - acc: 0.3051 - val_loss: 1.7190 - val_acc: 0.2518\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.7263 - acc: 0.2904 - val_loss: 1.6765 - val_acc: 0.3741\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 1.7040 - acc: 0.2941 - val_loss: 1.5992 - val_acc: 0.4245\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 5s 288ms/step - loss: 1.6547 - acc: 0.3163 - val_loss: 1.4989 - val_acc: 0.4245\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.6150 - acc: 0.3234 - val_loss: 1.4623 - val_acc: 0.4676\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 1.6106 - acc: 0.3711 - val_loss: 1.4288 - val_acc: 0.4964\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 5s 281ms/step - loss: 1.5851 - acc: 0.3676 - val_loss: 1.4305 - val_acc: 0.4460\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.6174 - acc: 0.3928 - val_loss: 1.4370 - val_acc: 0.5180\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.6107 - acc: 0.3824 - val_loss: 1.4239 - val_acc: 0.4604\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 5s 281ms/step - loss: 1.6163 - acc: 0.3500 - val_loss: 1.4434 - val_acc: 0.4676\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.5970 - acc: 0.3897 - val_loss: 1.3842 - val_acc: 0.4460\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.5835 - acc: 0.3603 - val_loss: 1.4585 - val_acc: 0.4245\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 5s 284ms/step - loss: 1.5436 - acc: 0.3971 - val_loss: 1.4054 - val_acc: 0.4317\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 5s 283ms/step - loss: 1.5060 - acc: 0.4151 - val_loss: 1.3516 - val_acc: 0.4676\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 5s 288ms/step - loss: 1.5226 - acc: 0.4112 - val_loss: 1.3881 - val_acc: 0.4460\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 5s 304ms/step - loss: 1.5157 - acc: 0.4296 - val_loss: 1.4042 - val_acc: 0.4460\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 1.5662 - acc: 0.4120 - val_loss: 1.3606 - val_acc: 0.4460\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 5s 304ms/step - loss: 1.4925 - acc: 0.4449 - val_loss: 1.3188 - val_acc: 0.4676\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.5025 - acc: 0.4596 - val_loss: 1.3134 - val_acc: 0.4964\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 5s 299ms/step - loss: 1.5435 - acc: 0.4118 - val_loss: 1.3359 - val_acc: 0.4964\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.4946 - acc: 0.4484 - val_loss: 1.3325 - val_acc: 0.4892\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 1.4891 - acc: 0.4375 - val_loss: 1.3381 - val_acc: 0.4748\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 5s 276ms/step - loss: 1.4994 - acc: 0.4373 - val_loss: 1.3242 - val_acc: 0.4676\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.5308 - acc: 0.4263 - val_loss: 1.3067 - val_acc: 0.5108\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 1.5287 - acc: 0.4301 - val_loss: 1.3533 - val_acc: 0.4892\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 5s 284ms/step - loss: 1.4259 - acc: 0.4597 - val_loss: 1.2963 - val_acc: 0.5683\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.4170 - acc: 0.4887 - val_loss: 1.2792 - val_acc: 0.4532\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.4863 - acc: 0.3973 - val_loss: 1.3043 - val_acc: 0.5612\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 5s 284ms/step - loss: 1.4149 - acc: 0.4816 - val_loss: 1.2500 - val_acc: 0.5108\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.4402 - acc: 0.4632 - val_loss: 1.2667 - val_acc: 0.5180\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 5s 290ms/step - loss: 1.3809 - acc: 0.4411 - val_loss: 1.2504 - val_acc: 0.5971\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 5s 282ms/step - loss: 1.3793 - acc: 0.4924 - val_loss: 1.2087 - val_acc: 0.5180\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 5s 283ms/step - loss: 1.3126 - acc: 0.5106 - val_loss: 1.1152 - val_acc: 0.5971\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 1.3549 - acc: 0.4928 - val_loss: 1.1519 - val_acc: 0.5468\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 5s 306ms/step - loss: 1.3608 - acc: 0.4558 - val_loss: 1.1775 - val_acc: 0.5468\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 5s 304ms/step - loss: 1.3072 - acc: 0.4669 - val_loss: 1.1862 - val_acc: 0.6043\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.3685 - acc: 0.4820 - val_loss: 1.1236 - val_acc: 0.5540\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.2227 - acc: 0.5516 - val_loss: 1.1322 - val_acc: 0.5827\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.3696 - acc: 0.4564 - val_loss: 1.1171 - val_acc: 0.5468\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 5s 288ms/step - loss: 1.1972 - acc: 0.5440 - val_loss: 1.1916 - val_acc: 0.5252\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 5s 284ms/step - loss: 1.3089 - acc: 0.5117 - val_loss: 1.1414 - val_acc: 0.5468\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.3171 - acc: 0.4963 - val_loss: 1.1307 - val_acc: 0.5540\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 5s 280ms/step - loss: 1.3486 - acc: 0.4564 - val_loss: 1.2063 - val_acc: 0.6043\n",
      "{'batch_size': 16, 'epochs': 50, 'init_mode': 'uniform', 'rate': 0.2}\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 5s 318ms/step - loss: 1.7681 - acc: 0.2385 - val_loss: 1.7392 - val_acc: 0.2374\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 5s 307ms/step - loss: 1.7553 - acc: 0.2465 - val_loss: 1.7534 - val_acc: 0.2446\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 5s 307ms/step - loss: 1.7569 - acc: 0.2428 - val_loss: 1.7315 - val_acc: 0.2374\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 5s 298ms/step - loss: 1.7411 - acc: 0.2130 - val_loss: 1.7293 - val_acc: 0.3094\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 1.7370 - acc: 0.2537 - val_loss: 1.7105 - val_acc: 0.3022\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 1.7187 - acc: 0.2938 - val_loss: 1.6775 - val_acc: 0.2518\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.7400 - acc: 0.2610 - val_loss: 1.6946 - val_acc: 0.3525\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 1.6943 - acc: 0.3566 - val_loss: 1.5948 - val_acc: 0.3885\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 5s 278ms/step - loss: 1.6279 - acc: 0.3713 - val_loss: 1.5336 - val_acc: 0.4029\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.6450 - acc: 0.3640 - val_loss: 1.5563 - val_acc: 0.4173\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 5s 277ms/step - loss: 1.6076 - acc: 0.3570 - val_loss: 1.4637 - val_acc: 0.4748\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.5967 - acc: 0.3640 - val_loss: 1.4714 - val_acc: 0.4317\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.5964 - acc: 0.3967 - val_loss: 1.4610 - val_acc: 0.4460\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.5323 - acc: 0.4081 - val_loss: 1.4521 - val_acc: 0.4245\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 1.6098 - acc: 0.3856 - val_loss: 1.4518 - val_acc: 0.4964\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 5s 278ms/step - loss: 1.6014 - acc: 0.3937 - val_loss: 1.4268 - val_acc: 0.4748\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.5855 - acc: 0.3824 - val_loss: 1.4220 - val_acc: 0.4604\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.5456 - acc: 0.4008 - val_loss: 1.4238 - val_acc: 0.4748\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.5704 - acc: 0.3715 - val_loss: 1.4029 - val_acc: 0.5036\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 1.5154 - acc: 0.4625 - val_loss: 1.3742 - val_acc: 0.4604\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 5s 307ms/step - loss: 1.5369 - acc: 0.4086 - val_loss: 1.3520 - val_acc: 0.5036\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 1.5134 - acc: 0.4084 - val_loss: 1.3425 - val_acc: 0.4676\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 5s 299ms/step - loss: 1.5215 - acc: 0.3965 - val_loss: 1.3840 - val_acc: 0.5252\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 1.5243 - acc: 0.4265 - val_loss: 1.3492 - val_acc: 0.5108\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.4544 - acc: 0.4339 - val_loss: 1.3140 - val_acc: 0.5324\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 5s 279ms/step - loss: 1.5179 - acc: 0.4049 - val_loss: 1.3813 - val_acc: 0.4964\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.4753 - acc: 0.4116 - val_loss: 1.3629 - val_acc: 0.5683\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 5s 288ms/step - loss: 1.4233 - acc: 0.4449 - val_loss: 1.2988 - val_acc: 0.4748\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 5s 284ms/step - loss: 1.4917 - acc: 0.4269 - val_loss: 1.3560 - val_acc: 0.5252\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 5s 290ms/step - loss: 1.5052 - acc: 0.4265 - val_loss: 1.2886 - val_acc: 0.5252\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 5s 284ms/step - loss: 1.4821 - acc: 0.4118 - val_loss: 1.2692 - val_acc: 0.5827\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.3993 - acc: 0.4417 - val_loss: 1.2184 - val_acc: 0.5683\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.3880 - acc: 0.4452 - val_loss: 1.2428 - val_acc: 0.5252\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 5s 288ms/step - loss: 1.4779 - acc: 0.4045 - val_loss: 1.2647 - val_acc: 0.5180\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.3799 - acc: 0.4738 - val_loss: 1.2624 - val_acc: 0.5827\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 5s 279ms/step - loss: 1.3340 - acc: 0.4740 - val_loss: 1.2513 - val_acc: 0.5252\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.4009 - acc: 0.4671 - val_loss: 1.2148 - val_acc: 0.5396\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 5s 304ms/step - loss: 1.3964 - acc: 0.4671 - val_loss: 1.1881 - val_acc: 0.5827\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 5s 317ms/step - loss: 1.3239 - acc: 0.4853 - val_loss: 1.1813 - val_acc: 0.6331\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 1.3410 - acc: 0.4638 - val_loss: 1.1611 - val_acc: 0.6115\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.3669 - acc: 0.5002 - val_loss: 1.2029 - val_acc: 0.5899\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 5s 306ms/step - loss: 1.3168 - acc: 0.5257 - val_loss: 1.1683 - val_acc: 0.5683\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 1.3423 - acc: 0.4822 - val_loss: 1.1872 - val_acc: 0.5468\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.3180 - acc: 0.5069 - val_loss: 1.1397 - val_acc: 0.5971\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 5s 288ms/step - loss: 1.2852 - acc: 0.4928 - val_loss: 1.1406 - val_acc: 0.5827\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 1.2476 - acc: 0.5331 - val_loss: 1.1282 - val_acc: 0.5899\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 5s 290ms/step - loss: 1.2860 - acc: 0.5076 - val_loss: 1.1107 - val_acc: 0.5755\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 5s 283ms/step - loss: 1.2830 - acc: 0.5037 - val_loss: 1.1605 - val_acc: 0.5108\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 1.2577 - acc: 0.4892 - val_loss: 1.1830 - val_acc: 0.5899\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 5s 284ms/step - loss: 1.2733 - acc: 0.5481 - val_loss: 1.1887 - val_acc: 0.5612\n",
      "{'batch_size': 16, 'epochs': 50, 'init_mode': 'uniform', 'rate': 0.5}\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 1.7758 - acc: 0.2240 - val_loss: 1.7496 - val_acc: 0.2230\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 5s 301ms/step - loss: 1.7385 - acc: 0.2870 - val_loss: 1.7458 - val_acc: 0.2374\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 5s 309ms/step - loss: 1.7579 - acc: 0.2608 - val_loss: 1.7325 - val_acc: 0.2950\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 5s 304ms/step - loss: 1.7547 - acc: 0.2574 - val_loss: 1.7287 - val_acc: 0.2950\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 1.7366 - acc: 0.2608 - val_loss: 1.7211 - val_acc: 0.2446\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 5s 298ms/step - loss: 1.7133 - acc: 0.2830 - val_loss: 1.6730 - val_acc: 0.3381\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.7020 - acc: 0.3161 - val_loss: 1.6156 - val_acc: 0.4245\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.6775 - acc: 0.3456 - val_loss: 1.5576 - val_acc: 0.4101\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.6609 - acc: 0.3193 - val_loss: 1.4900 - val_acc: 0.3957\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 5s 282ms/step - loss: 1.5786 - acc: 0.4004 - val_loss: 1.4818 - val_acc: 0.3957\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 1.6607 - acc: 0.3346 - val_loss: 1.4862 - val_acc: 0.4676\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 5s 278ms/step - loss: 1.6006 - acc: 0.3973 - val_loss: 1.4249 - val_acc: 0.4748\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.5961 - acc: 0.3531 - val_loss: 1.4118 - val_acc: 0.4820\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.5471 - acc: 0.4149 - val_loss: 1.3890 - val_acc: 0.4964\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.6098 - acc: 0.3750 - val_loss: 1.4201 - val_acc: 0.4820\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.5930 - acc: 0.4079 - val_loss: 1.4357 - val_acc: 0.4604\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.6156 - acc: 0.4010 - val_loss: 1.4477 - val_acc: 0.4317\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 5s 278ms/step - loss: 1.6053 - acc: 0.3973 - val_loss: 1.4321 - val_acc: 0.4676\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.5351 - acc: 0.4225 - val_loss: 1.3926 - val_acc: 0.4532\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 5s 301ms/step - loss: 1.5778 - acc: 0.3897 - val_loss: 1.4127 - val_acc: 0.4532\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 1.5985 - acc: 0.3640 - val_loss: 1.4013 - val_acc: 0.4173\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 5s 298ms/step - loss: 1.5098 - acc: 0.4337 - val_loss: 1.4004 - val_acc: 0.4532\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 1.5207 - acc: 0.4225 - val_loss: 1.3637 - val_acc: 0.4676\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.5264 - acc: 0.4333 - val_loss: 1.3731 - val_acc: 0.4532\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 5s 288ms/step - loss: 1.5587 - acc: 0.3822 - val_loss: 1.3869 - val_acc: 0.4532\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.5521 - acc: 0.3897 - val_loss: 1.4096 - val_acc: 0.4460\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 1.5493 - acc: 0.4191 - val_loss: 1.3419 - val_acc: 0.4820\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 5s 281ms/step - loss: 1.5356 - acc: 0.4258 - val_loss: 1.3440 - val_acc: 0.4892\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.4412 - acc: 0.4452 - val_loss: 1.2886 - val_acc: 0.5108\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.5735 - acc: 0.3715 - val_loss: 1.3253 - val_acc: 0.5252\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 1.5124 - acc: 0.4265 - val_loss: 1.2778 - val_acc: 0.5252\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 5s 273ms/step - loss: 1.5228 - acc: 0.3965 - val_loss: 1.3001 - val_acc: 0.5108\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 1.4620 - acc: 0.4522 - val_loss: 1.2273 - val_acc: 0.5324\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.4832 - acc: 0.4413 - val_loss: 1.2712 - val_acc: 0.5755\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.4787 - acc: 0.4300 - val_loss: 1.2973 - val_acc: 0.5180\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.4462 - acc: 0.4263 - val_loss: 1.2578 - val_acc: 0.5108\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.4271 - acc: 0.4738 - val_loss: 1.1864 - val_acc: 0.5612\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 5s 306ms/step - loss: 1.3725 - acc: 0.4848 - val_loss: 1.1450 - val_acc: 0.5683\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 5s 312ms/step - loss: 1.4050 - acc: 0.4449 - val_loss: 1.1123 - val_acc: 0.5899\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 1.3783 - acc: 0.4922 - val_loss: 1.1379 - val_acc: 0.5324\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 1.4426 - acc: 0.4376 - val_loss: 1.1276 - val_acc: 0.5899\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 5s 299ms/step - loss: 1.3197 - acc: 0.4779 - val_loss: 1.1198 - val_acc: 0.5612\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 5s 290ms/step - loss: 1.3644 - acc: 0.5033 - val_loss: 1.1135 - val_acc: 0.5755\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.4163 - acc: 0.4597 - val_loss: 1.1082 - val_acc: 0.5827\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 5s 283ms/step - loss: 1.3784 - acc: 0.4774 - val_loss: 1.1153 - val_acc: 0.5971\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.3548 - acc: 0.4816 - val_loss: 1.0933 - val_acc: 0.6043\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 5s 290ms/step - loss: 1.2952 - acc: 0.5184 - val_loss: 1.0740 - val_acc: 0.5971\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 5s 284ms/step - loss: 1.3047 - acc: 0.4963 - val_loss: 1.1023 - val_acc: 0.5827\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.3022 - acc: 0.4706 - val_loss: 1.0753 - val_acc: 0.5683\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 5s 280ms/step - loss: 1.3263 - acc: 0.5035 - val_loss: 1.0798 - val_acc: 0.6331\n",
      "{'batch_size': 16, 'epochs': 50, 'init_mode': 'normal', 'rate': 0}\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 6s 325ms/step - loss: 1.7705 - acc: 0.2169 - val_loss: 1.7325 - val_acc: 0.2878\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 1.7570 - acc: 0.2355 - val_loss: 1.7217 - val_acc: 0.3237\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 1.7310 - acc: 0.2541 - val_loss: 1.7141 - val_acc: 0.3094\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 5s 311ms/step - loss: 1.7223 - acc: 0.2610 - val_loss: 1.6574 - val_acc: 0.4388\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 5s 288ms/step - loss: 1.7078 - acc: 0.3238 - val_loss: 1.5937 - val_acc: 0.3885\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.6466 - acc: 0.3637 - val_loss: 1.5514 - val_acc: 0.3957\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 1.6305 - acc: 0.3419 - val_loss: 1.5042 - val_acc: 0.4388\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 5s 280ms/step - loss: 1.6186 - acc: 0.3520 - val_loss: 1.4855 - val_acc: 0.4820\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 1.6322 - acc: 0.3309 - val_loss: 1.4726 - val_acc: 0.4317\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 5s 283ms/step - loss: 1.5081 - acc: 0.4186 - val_loss: 1.4117 - val_acc: 0.4748\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 5s 288ms/step - loss: 1.5855 - acc: 0.3605 - val_loss: 1.4196 - val_acc: 0.4317\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 5s 277ms/step - loss: 1.6243 - acc: 0.3420 - val_loss: 1.4464 - val_acc: 0.4820\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 1.5302 - acc: 0.4081 - val_loss: 1.3760 - val_acc: 0.4676\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 5s 283ms/step - loss: 1.4994 - acc: 0.4300 - val_loss: 1.3955 - val_acc: 0.4460\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 1.5628 - acc: 0.3715 - val_loss: 1.3866 - val_acc: 0.5180\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.5946 - acc: 0.3789 - val_loss: 1.4332 - val_acc: 0.4388\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 1.5001 - acc: 0.4153 - val_loss: 1.3388 - val_acc: 0.4676\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 5s 279ms/step - loss: 1.4989 - acc: 0.4374 - val_loss: 1.2786 - val_acc: 0.5108\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.4921 - acc: 0.4407 - val_loss: 1.3151 - val_acc: 0.5180\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 1.5185 - acc: 0.4114 - val_loss: 1.3321 - val_acc: 0.5324\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 5s 305ms/step - loss: 1.3839 - acc: 0.4885 - val_loss: 1.2173 - val_acc: 0.5827\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 5s 299ms/step - loss: 1.3989 - acc: 0.4560 - val_loss: 1.3340 - val_acc: 0.4748\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 5s 304ms/step - loss: 1.3871 - acc: 0.4890 - val_loss: 1.2350 - val_acc: 0.6043\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 1.3284 - acc: 0.4926 - val_loss: 1.2213 - val_acc: 0.5036\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.4014 - acc: 0.5074 - val_loss: 1.3490 - val_acc: 0.4604\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 1.3830 - acc: 0.4522 - val_loss: 1.2732 - val_acc: 0.4460\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 1.3846 - acc: 0.4558 - val_loss: 1.1801 - val_acc: 0.5827\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 5s 281ms/step - loss: 1.3060 - acc: 0.4887 - val_loss: 1.2147 - val_acc: 0.4964\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.3074 - acc: 0.4816 - val_loss: 1.1275 - val_acc: 0.6187\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 5s 288ms/step - loss: 1.2317 - acc: 0.5035 - val_loss: 1.1235 - val_acc: 0.5612\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.4364 - acc: 0.4413 - val_loss: 1.2046 - val_acc: 0.5036\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 5s 284ms/step - loss: 1.3385 - acc: 0.4857 - val_loss: 1.1952 - val_acc: 0.5468\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 1.2212 - acc: 0.5110 - val_loss: 1.1370 - val_acc: 0.5612\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 1.2238 - acc: 0.5401 - val_loss: 1.0873 - val_acc: 0.5612\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.2113 - acc: 0.5299 - val_loss: 1.0641 - val_acc: 0.5612\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 5s 281ms/step - loss: 1.2172 - acc: 0.5295 - val_loss: 1.2118 - val_acc: 0.5396\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 1.1795 - acc: 0.5661 - val_loss: 1.0928 - val_acc: 0.6187\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 5s 305ms/step - loss: 1.2814 - acc: 0.4896 - val_loss: 1.1313 - val_acc: 0.5540\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 5s 298ms/step - loss: 1.2345 - acc: 0.5184 - val_loss: 1.0705 - val_acc: 0.5899\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 5s 298ms/step - loss: 1.1785 - acc: 0.5882 - val_loss: 1.1624 - val_acc: 0.5755\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 5s 312ms/step - loss: 1.2241 - acc: 0.5257 - val_loss: 1.1136 - val_acc: 0.6259\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 1.1705 - acc: 0.5547 - val_loss: 1.2247 - val_acc: 0.5540\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.1359 - acc: 0.5479 - val_loss: 1.2113 - val_acc: 0.5755\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 1.1383 - acc: 0.5808 - val_loss: 1.0762 - val_acc: 0.5683\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 1.1268 - acc: 0.5662 - val_loss: 1.0927 - val_acc: 0.5180\n",
      "{'batch_size': 16, 'epochs': 50, 'init_mode': 'normal', 'rate': 0.2}\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 6s 328ms/step - loss: 1.7679 - acc: 0.1945 - val_loss: 1.7403 - val_acc: 0.2302\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 1.7494 - acc: 0.2652 - val_loss: 1.7316 - val_acc: 0.2518\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 1.7435 - acc: 0.2610 - val_loss: 1.7262 - val_acc: 0.2662\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 5s 306ms/step - loss: 1.7533 - acc: 0.2715 - val_loss: 1.7140 - val_acc: 0.3237\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 1.7129 - acc: 0.2831 - val_loss: 1.6884 - val_acc: 0.3309\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.7111 - acc: 0.3047 - val_loss: 1.6548 - val_acc: 0.3309\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.6530 - acc: 0.3341 - val_loss: 1.6509 - val_acc: 0.2878\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 5s 290ms/step - loss: 1.6373 - acc: 0.3202 - val_loss: 1.6062 - val_acc: 0.3453\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 1.6574 - acc: 0.3089 - val_loss: 1.5756 - val_acc: 0.3957\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 5s 283ms/step - loss: 1.6368 - acc: 0.3453 - val_loss: 1.5150 - val_acc: 0.4388\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 1.5946 - acc: 0.3787 - val_loss: 1.4832 - val_acc: 0.4245\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 5s 290ms/step - loss: 1.5673 - acc: 0.4079 - val_loss: 1.4573 - val_acc: 0.4460\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.5490 - acc: 0.3789 - val_loss: 1.4413 - val_acc: 0.4532\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 5s 288ms/step - loss: 1.5664 - acc: 0.3527 - val_loss: 1.4753 - val_acc: 0.4676\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 5s 283ms/step - loss: 1.4904 - acc: 0.4521 - val_loss: 1.4279 - val_acc: 0.4676\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 1.5424 - acc: 0.3566 - val_loss: 1.4120 - val_acc: 0.4964\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 1.5204 - acc: 0.3860 - val_loss: 1.3807 - val_acc: 0.4748\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 1.4757 - acc: 0.4374 - val_loss: 1.5058 - val_acc: 0.4820\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.5218 - acc: 0.3971 - val_loss: 1.4420 - val_acc: 0.4820\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 5s 305ms/step - loss: 1.4988 - acc: 0.4225 - val_loss: 1.3547 - val_acc: 0.5324\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 1.4885 - acc: 0.4006 - val_loss: 1.3747 - val_acc: 0.5396\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 5s 308ms/step - loss: 1.5132 - acc: 0.4154 - val_loss: 1.3489 - val_acc: 0.5324\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 5s 301ms/step - loss: 1.4643 - acc: 0.4263 - val_loss: 1.3860 - val_acc: 0.4604\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 1.4126 - acc: 0.4450 - val_loss: 1.3074 - val_acc: 0.4892\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.4559 - acc: 0.4269 - val_loss: 1.3434 - val_acc: 0.5180\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 5s 298ms/step - loss: 1.4633 - acc: 0.4522 - val_loss: 1.3203 - val_acc: 0.5540\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.4203 - acc: 0.4525 - val_loss: 1.2555 - val_acc: 0.5612\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 5s 301ms/step - loss: 1.4655 - acc: 0.4227 - val_loss: 1.2808 - val_acc: 0.5396\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 5s 283ms/step - loss: 1.4601 - acc: 0.4153 - val_loss: 1.3013 - val_acc: 0.5540\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 1.3628 - acc: 0.5037 - val_loss: 1.2502 - val_acc: 0.5252\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 5s 281ms/step - loss: 1.4236 - acc: 0.4484 - val_loss: 1.2131 - val_acc: 0.5612\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.3756 - acc: 0.4707 - val_loss: 1.1955 - val_acc: 0.5612\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 5s 290ms/step - loss: 1.2877 - acc: 0.5299 - val_loss: 1.1547 - val_acc: 0.5899\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 1.3458 - acc: 0.4562 - val_loss: 1.1009 - val_acc: 0.5899\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 5s 278ms/step - loss: 1.3010 - acc: 0.5000 - val_loss: 1.3154 - val_acc: 0.4820\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.3688 - acc: 0.4560 - val_loss: 1.1502 - val_acc: 0.5396\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.3103 - acc: 0.5037 - val_loss: 1.1951 - val_acc: 0.5468\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 5s 304ms/step - loss: 1.2411 - acc: 0.4926 - val_loss: 1.0793 - val_acc: 0.5971\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 5s 313ms/step - loss: 1.2914 - acc: 0.4706 - val_loss: 1.1455 - val_acc: 0.5540\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 1.2446 - acc: 0.4959 - val_loss: 1.1131 - val_acc: 0.5899\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 5s 298ms/step - loss: 1.2992 - acc: 0.4961 - val_loss: 1.1096 - val_acc: 0.5827\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.3108 - acc: 0.4633 - val_loss: 1.2093 - val_acc: 0.4964\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 1.1991 - acc: 0.5294 - val_loss: 1.1010 - val_acc: 0.5971\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 5s 282ms/step - loss: 1.3460 - acc: 0.4490 - val_loss: 1.0909 - val_acc: 0.5612\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 5s 290ms/step - loss: 1.2331 - acc: 0.4855 - val_loss: 1.0315 - val_acc: 0.5971\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.2213 - acc: 0.4924 - val_loss: 1.0971 - val_acc: 0.5755\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.2141 - acc: 0.4848 - val_loss: 1.0540 - val_acc: 0.5612\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 1.2195 - acc: 0.5294 - val_loss: 1.0425 - val_acc: 0.6115\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.1260 - acc: 0.5703 - val_loss: 1.0202 - val_acc: 0.6259\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 1.1863 - acc: 0.5221 - val_loss: 0.9898 - val_acc: 0.5899\n",
      "{'batch_size': 16, 'epochs': 50, 'init_mode': 'normal', 'rate': 0.5}\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 6s 328ms/step - loss: 1.7800 - acc: 0.2353 - val_loss: 1.7437 - val_acc: 0.2302\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 5s 305ms/step - loss: 1.7566 - acc: 0.2465 - val_loss: 1.7318 - val_acc: 0.2518\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 5s 299ms/step - loss: 1.7399 - acc: 0.2242 - val_loss: 1.7264 - val_acc: 0.2230\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 1.7534 - acc: 0.2463 - val_loss: 1.7115 - val_acc: 0.2446\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 1.7249 - acc: 0.2834 - val_loss: 1.7033 - val_acc: 0.3597\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 5s 301ms/step - loss: 1.7382 - acc: 0.2721 - val_loss: 1.6771 - val_acc: 0.3165\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 5s 283ms/step - loss: 1.6811 - acc: 0.3414 - val_loss: 1.5933 - val_acc: 0.4029\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.7041 - acc: 0.3568 - val_loss: 1.6197 - val_acc: 0.3885\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 1.6835 - acc: 0.3088 - val_loss: 1.4759 - val_acc: 0.4604\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 5s 283ms/step - loss: 1.6015 - acc: 0.3533 - val_loss: 1.4425 - val_acc: 0.4964\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 1.6456 - acc: 0.3603 - val_loss: 1.4734 - val_acc: 0.4748\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 1.5777 - acc: 0.3932 - val_loss: 1.4153 - val_acc: 0.4748\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 5s 276ms/step - loss: 1.5890 - acc: 0.4119 - val_loss: 1.4201 - val_acc: 0.4964\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 1.6199 - acc: 0.3309 - val_loss: 1.4301 - val_acc: 0.4820\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 5s 290ms/step - loss: 1.5650 - acc: 0.4004 - val_loss: 1.3834 - val_acc: 0.4892\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.5348 - acc: 0.4261 - val_loss: 1.3693 - val_acc: 0.4748\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 5s 288ms/step - loss: 1.5923 - acc: 0.3934 - val_loss: 1.3980 - val_acc: 0.4964\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 5s 284ms/step - loss: 1.5517 - acc: 0.4517 - val_loss: 1.3594 - val_acc: 0.4892\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 1.5638 - acc: 0.3633 - val_loss: 1.3645 - val_acc: 0.4748\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 5s 313ms/step - loss: 1.5490 - acc: 0.3748 - val_loss: 1.3515 - val_acc: 0.4964\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 5s 306ms/step - loss: 1.5644 - acc: 0.4045 - val_loss: 1.3623 - val_acc: 0.4820\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 5s 308ms/step - loss: 1.5703 - acc: 0.3748 - val_loss: 1.3902 - val_acc: 0.4892\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 5s 298ms/step - loss: 1.5883 - acc: 0.3603 - val_loss: 1.3744 - val_acc: 0.4460\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 1.5307 - acc: 0.3681 - val_loss: 1.3532 - val_acc: 0.5036\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 1.5103 - acc: 0.4155 - val_loss: 1.2887 - val_acc: 0.5108\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 5s 298ms/step - loss: 1.4880 - acc: 0.4632 - val_loss: 1.2671 - val_acc: 0.5468\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 5s 290ms/step - loss: 1.4752 - acc: 0.4231 - val_loss: 1.2846 - val_acc: 0.5468\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 5s 282ms/step - loss: 1.5198 - acc: 0.4045 - val_loss: 1.2870 - val_acc: 0.5108\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 1.4204 - acc: 0.4411 - val_loss: 1.2285 - val_acc: 0.4964\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.3932 - acc: 0.4560 - val_loss: 1.1926 - val_acc: 0.5252\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 5s 298ms/step - loss: 1.3664 - acc: 0.4669 - val_loss: 1.1853 - val_acc: 0.5108\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 1.4931 - acc: 0.4043 - val_loss: 1.2589 - val_acc: 0.5468\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 5s 281ms/step - loss: 1.4237 - acc: 0.4452 - val_loss: 1.1741 - val_acc: 0.5396\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 5s 280ms/step - loss: 1.4064 - acc: 0.4338 - val_loss: 1.2567 - val_acc: 0.5612\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 5s 288ms/step - loss: 1.4490 - acc: 0.4339 - val_loss: 1.1843 - val_acc: 0.5755\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 1.3831 - acc: 0.4706 - val_loss: 1.1484 - val_acc: 0.5755\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 5s 282ms/step - loss: 1.3119 - acc: 0.5037 - val_loss: 1.1571 - val_acc: 0.5540\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 5s 312ms/step - loss: 1.2980 - acc: 0.5000 - val_loss: 1.1348 - val_acc: 0.5683\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 5s 304ms/step - loss: 1.3595 - acc: 0.4848 - val_loss: 1.4164 - val_acc: 0.4460\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 5s 304ms/step - loss: 1.4362 - acc: 0.4411 - val_loss: 1.1668 - val_acc: 0.5540\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 1.3215 - acc: 0.4855 - val_loss: 1.1806 - val_acc: 0.5396\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 5s 301ms/step - loss: 1.3426 - acc: 0.4926 - val_loss: 1.0979 - val_acc: 0.5899\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 1.2807 - acc: 0.5325 - val_loss: 1.0580 - val_acc: 0.5827\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.2486 - acc: 0.4957 - val_loss: 1.0672 - val_acc: 0.6259\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 5s 290ms/step - loss: 1.3192 - acc: 0.4740 - val_loss: 1.0387 - val_acc: 0.5971\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 5s 281ms/step - loss: 1.3178 - acc: 0.4890 - val_loss: 1.0991 - val_acc: 0.6043\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 5s 281ms/step - loss: 1.2420 - acc: 0.5662 - val_loss: 1.0207 - val_acc: 0.6043\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.3361 - acc: 0.4887 - val_loss: 1.1943 - val_acc: 0.5468\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 1.3599 - acc: 0.4779 - val_loss: 1.0870 - val_acc: 0.5971\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.2328 - acc: 0.5404 - val_loss: 1.0744 - val_acc: 0.5755\n",
      "{'batch_size': 16, 'epochs': 50, 'init_mode': 'zero', 'rate': 0}\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 6s 325ms/step - loss: 1.7907 - acc: 0.2240 - val_loss: 1.7892 - val_acc: 0.2302\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 1.7878 - acc: 0.2283 - val_loss: 1.7866 - val_acc: 0.2302\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 1.7860 - acc: 0.2205 - val_loss: 1.7842 - val_acc: 0.2302\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 5s 304ms/step - loss: 1.7830 - acc: 0.2242 - val_loss: 1.7816 - val_acc: 0.2302\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 1.7822 - acc: 0.2428 - val_loss: 1.7794 - val_acc: 0.2302\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 1.7777 - acc: 0.2206 - val_loss: 1.7773 - val_acc: 0.2302\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 5s 299ms/step - loss: 1.7784 - acc: 0.2171 - val_loss: 1.7753 - val_acc: 0.2302\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.7719 - acc: 0.2537 - val_loss: 1.7731 - val_acc: 0.2374\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.7732 - acc: 0.2207 - val_loss: 1.7711 - val_acc: 0.2374\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 5s 282ms/step - loss: 1.7715 - acc: 0.2387 - val_loss: 1.7695 - val_acc: 0.2374\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 1.7652 - acc: 0.2463 - val_loss: 1.7676 - val_acc: 0.2374\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 5s 279ms/step - loss: 1.7690 - acc: 0.2133 - val_loss: 1.7661 - val_acc: 0.2374\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 5s 298ms/step - loss: 1.7658 - acc: 0.2574 - val_loss: 1.7645 - val_acc: 0.2374\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 5s 280ms/step - loss: 1.7694 - acc: 0.2134 - val_loss: 1.7632 - val_acc: 0.2374\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 1.7560 - acc: 0.2613 - val_loss: 1.7618 - val_acc: 0.2374\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 5s 273ms/step - loss: 1.7682 - acc: 0.2096 - val_loss: 1.7604 - val_acc: 0.2374\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 5s 284ms/step - loss: 1.7655 - acc: 0.2355 - val_loss: 1.7592 - val_acc: 0.2374\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 1.7563 - acc: 0.2390 - val_loss: 1.7582 - val_acc: 0.2374\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 5s 284ms/step - loss: 1.7580 - acc: 0.2426 - val_loss: 1.7569 - val_acc: 0.2374\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 1.7560 - acc: 0.2387 - val_loss: 1.7558 - val_acc: 0.2374\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 5s 310ms/step - loss: 1.7568 - acc: 0.2206 - val_loss: 1.7548 - val_acc: 0.2374\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 5s 299ms/step - loss: 1.7560 - acc: 0.2496 - val_loss: 1.7538 - val_acc: 0.2374\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 1.7539 - acc: 0.2465 - val_loss: 1.7528 - val_acc: 0.2374\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 5s 301ms/step - loss: 1.7512 - acc: 0.2243 - val_loss: 1.7518 - val_acc: 0.2374\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 5s 281ms/step - loss: 1.7534 - acc: 0.2346 - val_loss: 1.7511 - val_acc: 0.2374\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.7613 - acc: 0.2426 - val_loss: 1.7503 - val_acc: 0.2374\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 1.7397 - acc: 0.2647 - val_loss: 1.7495 - val_acc: 0.2374\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.7459 - acc: 0.2132 - val_loss: 1.7487 - val_acc: 0.2374\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 5s 284ms/step - loss: 1.7598 - acc: 0.2687 - val_loss: 1.7480 - val_acc: 0.2374\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 1.7515 - acc: 0.1985 - val_loss: 1.7474 - val_acc: 0.2374\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 5s 278ms/step - loss: 1.7394 - acc: 0.2576 - val_loss: 1.7467 - val_acc: 0.2374\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 1.7463 - acc: 0.2169 - val_loss: 1.7461 - val_acc: 0.2374\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.7482 - acc: 0.2387 - val_loss: 1.7455 - val_acc: 0.2374\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 1.7487 - acc: 0.2318 - val_loss: 1.7449 - val_acc: 0.2374\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.7501 - acc: 0.2244 - val_loss: 1.7445 - val_acc: 0.2374\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 5s 283ms/step - loss: 1.7450 - acc: 0.2426 - val_loss: 1.7440 - val_acc: 0.2374\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 5s 284ms/step - loss: 1.7459 - acc: 0.2279 - val_loss: 1.7434 - val_acc: 0.2374\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 5s 299ms/step - loss: 1.7405 - acc: 0.2539 - val_loss: 1.7430 - val_acc: 0.2374\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 1.7377 - acc: 0.2283 - val_loss: 1.7426 - val_acc: 0.2374\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 1.7425 - acc: 0.2277 - val_loss: 1.7421 - val_acc: 0.2374\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 1.7607 - acc: 0.2498 - val_loss: 1.7418 - val_acc: 0.2374\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 1.7326 - acc: 0.2390 - val_loss: 1.7414 - val_acc: 0.2374\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.7512 - acc: 0.2214 - val_loss: 1.7412 - val_acc: 0.2374\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 5s 301ms/step - loss: 1.7483 - acc: 0.2279 - val_loss: 1.7410 - val_acc: 0.2374\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.7358 - acc: 0.2390 - val_loss: 1.7405 - val_acc: 0.2374\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 5s 280ms/step - loss: 1.7328 - acc: 0.2533 - val_loss: 1.7402 - val_acc: 0.2374\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 1.7341 - acc: 0.2500 - val_loss: 1.7399 - val_acc: 0.2374\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.7472 - acc: 0.2166 - val_loss: 1.7396 - val_acc: 0.2374\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 5s 299ms/step - loss: 1.7516 - acc: 0.2243 - val_loss: 1.7394 - val_acc: 0.2374\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 5s 277ms/step - loss: 1.7352 - acc: 0.2320 - val_loss: 1.7392 - val_acc: 0.2374\n",
      "{'batch_size': 16, 'epochs': 50, 'init_mode': 'zero', 'rate': 0.2}\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 1.7906 - acc: 0.2130 - val_loss: 1.7888 - val_acc: 0.2302\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 1.7871 - acc: 0.2390 - val_loss: 1.7858 - val_acc: 0.2302\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 5s 309ms/step - loss: 1.7857 - acc: 0.2096 - val_loss: 1.7834 - val_acc: 0.2374\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 1.7806 - acc: 0.2760 - val_loss: 1.7810 - val_acc: 0.2374\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 5s 308ms/step - loss: 1.7820 - acc: 0.2096 - val_loss: 1.7787 - val_acc: 0.2374\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.7795 - acc: 0.2172 - val_loss: 1.7769 - val_acc: 0.2374\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.7737 - acc: 0.2721 - val_loss: 1.7747 - val_acc: 0.2374\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 1.7782 - acc: 0.1805 - val_loss: 1.7728 - val_acc: 0.2374\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.7713 - acc: 0.2428 - val_loss: 1.7711 - val_acc: 0.2374\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.7681 - acc: 0.2647 - val_loss: 1.7693 - val_acc: 0.2374\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.7727 - acc: 0.2242 - val_loss: 1.7678 - val_acc: 0.2374\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 5s 284ms/step - loss: 1.7661 - acc: 0.2318 - val_loss: 1.7661 - val_acc: 0.2374\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 5s 277ms/step - loss: 1.7698 - acc: 0.2244 - val_loss: 1.7646 - val_acc: 0.2374\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 1.7635 - acc: 0.2390 - val_loss: 1.7633 - val_acc: 0.2374\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.7587 - acc: 0.2569 - val_loss: 1.7619 - val_acc: 0.2374\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 5s 288ms/step - loss: 1.7649 - acc: 0.2242 - val_loss: 1.7604 - val_acc: 0.2374\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.7529 - acc: 0.2606 - val_loss: 1.7591 - val_acc: 0.2374\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.7616 - acc: 0.2240 - val_loss: 1.7577 - val_acc: 0.2374\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 5s 284ms/step - loss: 1.7565 - acc: 0.2387 - val_loss: 1.7565 - val_acc: 0.2374\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 5s 301ms/step - loss: 1.7565 - acc: 0.2426 - val_loss: 1.7556 - val_acc: 0.2374\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 5s 309ms/step - loss: 1.7563 - acc: 0.2277 - val_loss: 1.7545 - val_acc: 0.2374\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 1.7519 - acc: 0.2353 - val_loss: 1.7535 - val_acc: 0.2374\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.7603 - acc: 0.2311 - val_loss: 1.7527 - val_acc: 0.2374\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 1.7438 - acc: 0.2615 - val_loss: 1.7516 - val_acc: 0.2374\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.7517 - acc: 0.2279 - val_loss: 1.7508 - val_acc: 0.2374\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.7545 - acc: 0.2169 - val_loss: 1.7500 - val_acc: 0.2374\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.7465 - acc: 0.2539 - val_loss: 1.7493 - val_acc: 0.2374\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 1.7592 - acc: 0.2210 - val_loss: 1.7486 - val_acc: 0.2374\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.7508 - acc: 0.2062 - val_loss: 1.7480 - val_acc: 0.2374\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.7350 - acc: 0.2688 - val_loss: 1.7472 - val_acc: 0.2374\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.7618 - acc: 0.2240 - val_loss: 1.7466 - val_acc: 0.2374\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 5s 280ms/step - loss: 1.7404 - acc: 0.2389 - val_loss: 1.7460 - val_acc: 0.2374\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.7487 - acc: 0.2206 - val_loss: 1.7455 - val_acc: 0.2374\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 1.7446 - acc: 0.2496 - val_loss: 1.7450 - val_acc: 0.2374\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 5s 280ms/step - loss: 1.7429 - acc: 0.2424 - val_loss: 1.7444 - val_acc: 0.2374\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.7523 - acc: 0.2355 - val_loss: 1.7439 - val_acc: 0.2374\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 5s 287ms/step - loss: 1.7482 - acc: 0.2390 - val_loss: 1.7435 - val_acc: 0.2374\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 5s 307ms/step - loss: 1.7467 - acc: 0.2281 - val_loss: 1.7431 - val_acc: 0.2374\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 1.7517 - acc: 0.2062 - val_loss: 1.7427 - val_acc: 0.2374\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 5s 299ms/step - loss: 1.7466 - acc: 0.2576 - val_loss: 1.7425 - val_acc: 0.2374\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 5s 307ms/step - loss: 1.7322 - acc: 0.2574 - val_loss: 1.7420 - val_acc: 0.2374\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 1.7500 - acc: 0.2127 - val_loss: 1.7417 - val_acc: 0.2374\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 5s 288ms/step - loss: 1.7462 - acc: 0.2717 - val_loss: 1.7414 - val_acc: 0.2374\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 5s 290ms/step - loss: 1.7478 - acc: 0.2060 - val_loss: 1.7410 - val_acc: 0.2374\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.7242 - acc: 0.2537 - val_loss: 1.7406 - val_acc: 0.2374\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 1.7569 - acc: 0.2022 - val_loss: 1.7403 - val_acc: 0.2374\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 5s 281ms/step - loss: 1.7289 - acc: 0.2500 - val_loss: 1.7401 - val_acc: 0.2374\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 5s 288ms/step - loss: 1.7554 - acc: 0.2246 - val_loss: 1.7398 - val_acc: 0.2374\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.7442 - acc: 0.2390 - val_loss: 1.7396 - val_acc: 0.2374\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.7334 - acc: 0.2389 - val_loss: 1.7393 - val_acc: 0.2374\n",
      "{'batch_size': 16, 'epochs': 50, 'init_mode': 'zero', 'rate': 0.5}\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 6s 325ms/step - loss: 1.7907 - acc: 0.2387 - val_loss: 1.7890 - val_acc: 0.2374\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 5s 305ms/step - loss: 1.7880 - acc: 0.2385 - val_loss: 1.7863 - val_acc: 0.2374\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 5s 301ms/step - loss: 1.7842 - acc: 0.2535 - val_loss: 1.7835 - val_acc: 0.2374\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 5s 313ms/step - loss: 1.7825 - acc: 0.2316 - val_loss: 1.7811 - val_acc: 0.2374\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 1.7812 - acc: 0.2246 - val_loss: 1.7789 - val_acc: 0.2374\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.7780 - acc: 0.2313 - val_loss: 1.7767 - val_acc: 0.2374\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.7765 - acc: 0.2318 - val_loss: 1.7745 - val_acc: 0.2374\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 1.7720 - acc: 0.2426 - val_loss: 1.7725 - val_acc: 0.2374\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.7764 - acc: 0.2283 - val_loss: 1.7709 - val_acc: 0.2374\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 5s 280ms/step - loss: 1.7679 - acc: 0.2530 - val_loss: 1.7691 - val_acc: 0.2374\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 1.7689 - acc: 0.2498 - val_loss: 1.7673 - val_acc: 0.2374\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 5s 281ms/step - loss: 1.7627 - acc: 0.2025 - val_loss: 1.7656 - val_acc: 0.2374\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 5s 298ms/step - loss: 1.7687 - acc: 0.2574 - val_loss: 1.7640 - val_acc: 0.2374\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 5s 288ms/step - loss: 1.7662 - acc: 0.2207 - val_loss: 1.7627 - val_acc: 0.2374\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 5s 279ms/step - loss: 1.7614 - acc: 0.2428 - val_loss: 1.7613 - val_acc: 0.2374\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 1.7673 - acc: 0.2279 - val_loss: 1.7599 - val_acc: 0.2374\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 5s 290ms/step - loss: 1.7572 - acc: 0.2390 - val_loss: 1.7588 - val_acc: 0.2374\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.7567 - acc: 0.2387 - val_loss: 1.7575 - val_acc: 0.2374\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 5s 290ms/step - loss: 1.7606 - acc: 0.2353 - val_loss: 1.7563 - val_acc: 0.2374\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 5s 309ms/step - loss: 1.7544 - acc: 0.2500 - val_loss: 1.7552 - val_acc: 0.2374\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 1.7564 - acc: 0.2242 - val_loss: 1.7541 - val_acc: 0.2374\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 5s 306ms/step - loss: 1.7552 - acc: 0.2390 - val_loss: 1.7532 - val_acc: 0.2374\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 1.7627 - acc: 0.2240 - val_loss: 1.7523 - val_acc: 0.2374\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 1.7442 - acc: 0.2279 - val_loss: 1.7513 - val_acc: 0.2374\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.7500 - acc: 0.2504 - val_loss: 1.7504 - val_acc: 0.2374\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.7555 - acc: 0.2277 - val_loss: 1.7497 - val_acc: 0.2374\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 5s 290ms/step - loss: 1.7400 - acc: 0.2502 - val_loss: 1.7488 - val_acc: 0.2374\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 5s 280ms/step - loss: 1.7602 - acc: 0.2210 - val_loss: 1.7482 - val_acc: 0.2374\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 1.7525 - acc: 0.2498 - val_loss: 1.7477 - val_acc: 0.2374\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 5s 301ms/step - loss: 1.7460 - acc: 0.2279 - val_loss: 1.7471 - val_acc: 0.2374\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.7557 - acc: 0.2096 - val_loss: 1.7465 - val_acc: 0.2374\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 5s 299ms/step - loss: 1.7462 - acc: 0.2610 - val_loss: 1.7458 - val_acc: 0.2374\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 5s 285ms/step - loss: 1.7420 - acc: 0.2205 - val_loss: 1.7452 - val_acc: 0.2374\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 5s 291ms/step - loss: 1.7505 - acc: 0.2394 - val_loss: 1.7447 - val_acc: 0.2374\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.7550 - acc: 0.2351 - val_loss: 1.7444 - val_acc: 0.2374\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 5s 279ms/step - loss: 1.7448 - acc: 0.2426 - val_loss: 1.7439 - val_acc: 0.2374\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 5s 298ms/step - loss: 1.7384 - acc: 0.2426 - val_loss: 1.7434 - val_acc: 0.2374\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 1.7570 - acc: 0.2320 - val_loss: 1.7431 - val_acc: 0.2374\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 1.7418 - acc: 0.2246 - val_loss: 1.7427 - val_acc: 0.2374\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 5s 305ms/step - loss: 1.7559 - acc: 0.2244 - val_loss: 1.7423 - val_acc: 0.2374\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 1.7373 - acc: 0.2279 - val_loss: 1.7420 - val_acc: 0.2374\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 1.7604 - acc: 0.2132 - val_loss: 1.7416 - val_acc: 0.2374\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 5s 283ms/step - loss: 1.7282 - acc: 0.2535 - val_loss: 1.7412 - val_acc: 0.2374\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 5s 286ms/step - loss: 1.7331 - acc: 0.2825 - val_loss: 1.7408 - val_acc: 0.2374\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 1.7415 - acc: 0.2353 - val_loss: 1.7404 - val_acc: 0.2374\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 5s 288ms/step - loss: 1.7507 - acc: 0.2207 - val_loss: 1.7401 - val_acc: 0.2374\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 5s 289ms/step - loss: 1.7376 - acc: 0.2351 - val_loss: 1.7398 - val_acc: 0.2374\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 5s 279ms/step - loss: 1.7256 - acc: 0.2719 - val_loss: 1.7395 - val_acc: 0.2374\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 5s 299ms/step - loss: 1.7589 - acc: 0.2022 - val_loss: 1.7393 - val_acc: 0.2374\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 1.7388 - acc: 0.2463 - val_loss: 1.7391 - val_acc: 0.2374\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 20211101\n",
    "np.random.seed(seed)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [8, 16]\n",
    "epochs = [50]\n",
    "rate = [0, 0.2, 0.5]\n",
    "init_mode = ['uniform', 'normal', 'zero']\n",
    "\n",
    "\n",
    "param_grid = [dict(batch_size=batch_size, epochs=epochs, rate=rate, init_mode = init_mode),\n",
    "             ]\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode = \"min\", patience =10)\n",
    "grid_results = []\n",
    "for step in ParameterGrid(param_grid):\n",
    "    print(step)\n",
    "     # create model\n",
    "    step_model = keras.Sequential()\n",
    "    step_model.add(keras.layers.Conv2D(filters=10, kernel_size=3, strides=1, padding = \"valid\", kernel_initializer=step['init_mode'],\n",
    "                                input_shape=(256, 256, 3)))\n",
    "    step_model.add(keras.layers.Activation('relu'))\n",
    "    step_model.add(keras.layers.MaxPool2D(pool_size=2, strides = 2))\n",
    "    step_model.add(keras.layers.Conv2D(filters=20, kernel_size=5, strides=2, padding = \"valid\", kernel_initializer=step['init_mode']))\n",
    "    step_model.add(keras.layers.Activation('relu'))\n",
    "    step_model.add(keras.layers.MaxPool2D(pool_size=2, strides = 2))\n",
    "    step_model.add(keras.layers.Conv2D(filters=40, kernel_size=5, strides=2, padding = \"valid\", kernel_initializer=step['init_mode']))\n",
    "    step_model.add(keras.layers.Activation('relu'))\n",
    "    step_model.add(keras.layers.MaxPool2D(pool_size=2, strides = 2))\n",
    "    step_model.add(keras.layers.Dropout(rate = step['rate']))\n",
    "\n",
    "\n",
    "    step_model.add(keras.layers.Flatten())\n",
    "    step_model.add(keras.layers.Dense(trainset.num_classes))\n",
    "    step_model.add(keras.layers.Activation('softmax'))\n",
    "    step_model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    step_history = step_model.fit_generator(\n",
    "        trainset,\n",
    "        steps_per_epoch=math.ceil(280 // step[\"batch_size\"]),\n",
    "        epochs=step['epochs'],\n",
    "        validation_data=validset, callbacks = [es],\n",
    "    shuffle = True)\n",
    "    grid_results.append([step['batch_size'],step['rate'],step['init_mode'],\n",
    "                        len(step_history.history['acc']),\n",
    "                        np.mean(step_history.history['acc'][-5:]),\n",
    "                        np.mean(step_history.history['val_acc'][-5:]), \n",
    "                        np.mean(step_history.history['loss'][-5:]),\n",
    "                        np.mean(step_history.history['val_loss'][-5:])])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98f423d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_results = pd.DataFrame(grid_results, columns = ['batch_size', 'rate', 'init_mode', 'nb_epochs', 'mean_last_5_acc', 'mean_last_5_val_acc', 'mean_last_5_loss', 'mean_last_5_val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a14a736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_results.to_csv('cnn_grid_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0381dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_results =pd.read_csv('cnn_grid_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1da57f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>rate</th>\n",
       "      <th>init_mode</th>\n",
       "      <th>nb_epochs</th>\n",
       "      <th>mean_last_5_acc</th>\n",
       "      <th>mean_last_5_val_acc</th>\n",
       "      <th>mean_last_5_loss</th>\n",
       "      <th>mean_last_5_val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>50</td>\n",
       "      <td>0.643460</td>\n",
       "      <td>0.637410</td>\n",
       "      <td>0.949868</td>\n",
       "      <td>1.023804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>normal</td>\n",
       "      <td>50</td>\n",
       "      <td>0.688459</td>\n",
       "      <td>0.634532</td>\n",
       "      <td>0.842090</td>\n",
       "      <td>1.052713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>normal</td>\n",
       "      <td>35</td>\n",
       "      <td>0.552206</td>\n",
       "      <td>0.633094</td>\n",
       "      <td>1.136759</td>\n",
       "      <td>1.057356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>39</td>\n",
       "      <td>0.680515</td>\n",
       "      <td>0.624460</td>\n",
       "      <td>0.870522</td>\n",
       "      <td>0.986763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>50</td>\n",
       "      <td>0.583476</td>\n",
       "      <td>0.621583</td>\n",
       "      <td>1.087361</td>\n",
       "      <td>1.059031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>50</td>\n",
       "      <td>0.493448</td>\n",
       "      <td>0.597122</td>\n",
       "      <td>1.317840</td>\n",
       "      <td>1.084931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>37</td>\n",
       "      <td>0.569853</td>\n",
       "      <td>0.592806</td>\n",
       "      <td>1.137326</td>\n",
       "      <td>1.041634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>normal</td>\n",
       "      <td>50</td>\n",
       "      <td>0.519101</td>\n",
       "      <td>0.592806</td>\n",
       "      <td>1.193436</td>\n",
       "      <td>1.040732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>normal</td>\n",
       "      <td>50</td>\n",
       "      <td>0.511521</td>\n",
       "      <td>0.585612</td>\n",
       "      <td>1.296975</td>\n",
       "      <td>1.095085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>45</td>\n",
       "      <td>0.553515</td>\n",
       "      <td>0.568345</td>\n",
       "      <td>1.159464</td>\n",
       "      <td>1.143710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  batch_size  rate init_mode  nb_epochs  mean_last_5_acc  \\\n",
       "1            1           8   0.2   uniform         50         0.643460   \n",
       "4            4           8   0.2    normal         50         0.688459   \n",
       "5            5           8   0.5    normal         35         0.552206   \n",
       "3            3           8   0.0    normal         39         0.680515   \n",
       "2            2           8   0.5   uniform         50         0.583476   \n",
       "11          11          16   0.5   uniform         50         0.493448   \n",
       "0            0           8   0.0   uniform         37         0.569853   \n",
       "13          13          16   0.2    normal         50         0.519101   \n",
       "14          14          16   0.5    normal         50         0.511521   \n",
       "12          12          16   0.0    normal         45         0.553515   \n",
       "\n",
       "    mean_last_5_val_acc  mean_last_5_loss  mean_last_5_val_loss  \n",
       "1              0.637410          0.949868              1.023804  \n",
       "4              0.634532          0.842090              1.052713  \n",
       "5              0.633094          1.136759              1.057356  \n",
       "3              0.624460          0.870522              0.986763  \n",
       "2              0.621583          1.087361              1.059031  \n",
       "11             0.597122          1.317840              1.084931  \n",
       "0              0.592806          1.137326              1.041634  \n",
       "13             0.592806          1.193436              1.040732  \n",
       "14             0.585612          1.296975              1.095085  \n",
       "12             0.568345          1.159464              1.143710  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grid_results.sort_values(by='mean_last_5_val_acc', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dea11c",
   "metadata": {},
   "source": [
    "The best accuracy is obtain with a batch_size = 8 , weights initiated with a uniform distribution and a drop out rate of 0.2. The best accuracy on the validtion set (averaged on the last 5 epochs) is around 64%. \n",
    "\n",
    "We can now fit a final time the model with the optimal parameters, predict the values for the test set and evaluate the final test set accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50f4ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = df_grid_results.sort_values(by='mean_last_5_val_acc', ascending = False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8deb5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 10s 294ms/step - loss: 1.7718 - acc: 0.2285 - val_loss: 1.7379 - val_acc: 0.2374\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 10s 286ms/step - loss: 1.7434 - acc: 0.2608 - val_loss: 1.7345 - val_acc: 0.3237\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 10s 287ms/step - loss: 1.7406 - acc: 0.2733 - val_loss: 1.6925 - val_acc: 0.3309\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 10s 288ms/step - loss: 1.7024 - acc: 0.3090 - val_loss: 1.5660 - val_acc: 0.3813\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.6409 - acc: 0.3857 - val_loss: 1.5441 - val_acc: 0.4388\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.5927 - acc: 0.3801 - val_loss: 1.4710 - val_acc: 0.4820\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.5514 - acc: 0.3948 - val_loss: 1.4160 - val_acc: 0.4820\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.5750 - acc: 0.4019 - val_loss: 1.4073 - val_acc: 0.4532\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.5460 - acc: 0.4036 - val_loss: 1.4042 - val_acc: 0.4964\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.5344 - acc: 0.3856 - val_loss: 1.4551 - val_acc: 0.4460\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.5428 - acc: 0.4145 - val_loss: 1.3758 - val_acc: 0.4676\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 10s 275ms/step - loss: 1.5138 - acc: 0.3930 - val_loss: 1.3825 - val_acc: 0.5108\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 10s 274ms/step - loss: 1.5401 - acc: 0.4179 - val_loss: 1.4642 - val_acc: 0.4317\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 10s 283ms/step - loss: 1.4919 - acc: 0.4162 - val_loss: 1.3072 - val_acc: 0.4892\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 1.4773 - acc: 0.4196 - val_loss: 1.3332 - val_acc: 0.4532\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.4360 - acc: 0.4412 - val_loss: 1.4213 - val_acc: 0.4317\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.4642 - acc: 0.4428 - val_loss: 1.3316 - val_acc: 0.4964\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.4421 - acc: 0.4715 - val_loss: 1.2751 - val_acc: 0.4748\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.3894 - acc: 0.4588 - val_loss: 1.2481 - val_acc: 0.5755\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 10s 285ms/step - loss: 1.3366 - acc: 0.4999 - val_loss: 1.3079 - val_acc: 0.5036\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 10s 284ms/step - loss: 1.3344 - acc: 0.4768 - val_loss: 1.2631 - val_acc: 0.5324\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.3159 - acc: 0.4858 - val_loss: 1.1333 - val_acc: 0.5612\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 10s 284ms/step - loss: 1.3139 - acc: 0.4714 - val_loss: 1.0955 - val_acc: 0.5971\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 10s 279ms/step - loss: 1.2444 - acc: 0.5089 - val_loss: 1.0774 - val_acc: 0.5971\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.1823 - acc: 0.5446 - val_loss: 1.0238 - val_acc: 0.6691\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.2080 - acc: 0.5304 - val_loss: 1.0183 - val_acc: 0.6187\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.2246 - acc: 0.5412 - val_loss: 1.0639 - val_acc: 0.5755\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 10s 273ms/step - loss: 1.1485 - acc: 0.5358 - val_loss: 0.9831 - val_acc: 0.6331\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.1415 - acc: 0.5394 - val_loss: 1.0456 - val_acc: 0.6403\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.1515 - acc: 0.5535 - val_loss: 1.0605 - val_acc: 0.6187\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 10s 278ms/step - loss: 1.2259 - acc: 0.5304 - val_loss: 1.0871 - val_acc: 0.5899\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 10s 276ms/step - loss: 1.0968 - acc: 0.5839 - val_loss: 1.0712 - val_acc: 0.6115\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.0807 - acc: 0.5893 - val_loss: 1.0388 - val_acc: 0.6043\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 1.0562 - acc: 0.5769 - val_loss: 1.1071 - val_acc: 0.5755\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 1.0508 - acc: 0.5787 - val_loss: 1.0194 - val_acc: 0.6475\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 10s 272ms/step - loss: 0.9819 - acc: 0.6393 - val_loss: 0.9896 - val_acc: 0.6619\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 10s 277ms/step - loss: 0.9998 - acc: 0.6428 - val_loss: 1.0305 - val_acc: 0.6475\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 10s 282ms/step - loss: 1.0418 - acc: 0.6053 - val_loss: 1.0934 - val_acc: 0.6259\n"
     ]
    }
   ],
   "source": [
    "final_cnn_model = keras.Sequential()\n",
    "final_cnn_model.add(keras.layers.Conv2D(filters=10, kernel_size=3, strides=1, padding = \"valid\", kernel_initializer=best_params.iloc[0]['init_mode'],input_shape=(256, 256, 3)))\n",
    "final_cnn_model.add(keras.layers.Activation('relu'))\n",
    "final_cnn_model.add(keras.layers.MaxPool2D(pool_size=2, strides = 2))\n",
    "final_cnn_model.add(keras.layers.Conv2D(filters=20, kernel_size=5, strides=2, padding = \"valid\", kernel_initializer=best_params.iloc[0]['init_mode']))\n",
    "final_cnn_model.add(keras.layers.Activation('relu'))\n",
    "final_cnn_model.add(keras.layers.MaxPool2D(pool_size=2, strides = 2))\n",
    "final_cnn_model.add(keras.layers.Conv2D(filters=40, kernel_size=5, strides=2, padding = \"valid\", kernel_initializer=best_params.iloc[0]['init_mode']))\n",
    "final_cnn_model.add(keras.layers.Activation('relu'))\n",
    "final_cnn_model.add(keras.layers.MaxPool2D(pool_size=2, strides = 2))\n",
    "final_cnn_model.add(keras.layers.Dropout(rate = best_params.iloc[0]['rate']))\n",
    "\n",
    "\n",
    "final_cnn_model.add(keras.layers.Flatten())\n",
    "final_cnn_model.add(keras.layers.Dense(trainset.num_classes))\n",
    "final_cnn_model.add(keras.layers.Activation('softmax'))\n",
    "final_cnn_model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "final_history = final_cnn_model.fit_generator(\n",
    "    trainset,\n",
    "    steps_per_epoch=math.ceil(280 // best_params.iloc[0][\"batch_size\"]),\n",
    "    epochs=100,\n",
    "    validation_data=validset, callbacks = [es],\n",
    "shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78522459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.27\n",
      "Test accuracy: 54.00%\n"
     ]
    }
   ],
   "source": [
    "(test_loss, test_accuracy) = final_cnn_model.evaluate_generator(testset)\n",
    "\n",
    "print('Test loss: {:.2f}'.format(test_loss))\n",
    "print('Test accuracy: {:.2f}%'.format(100*test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de326642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "\n",
    "# Plot loss values\n",
    "ax1.set_title('loss: {:.4f}'.format(final_history.history['val_loss'][-1]))\n",
    "ax1.plot(final_history.history['val_loss'], label='validation')\n",
    "ax1.plot(final_history.history['loss'], label='training')\n",
    "ax1.legend()\n",
    "\n",
    "# plot accuracy values\n",
    "ax2.set_title('accuracy: {:.2f}%'.format(final_history.history['val_acc'][-1]*100))\n",
    "ax2.plot(final_history.history['val_acc'], label='validation')\n",
    "ax2.plot(final_history.history['acc'], label='training')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734b6733",
   "metadata": {},
   "source": [
    "The architecture we tried here is only one of all the ones that were tested for this project. It has a simple architecture and is the one that achieved consistently the highest test accuracy for a lesser computational cost. Trying more complicated architectures often yielded in the model getting stuck in a local minimum where the model wasn't learning even when we increased the number of epochs and were much more expensive.  \n",
    "\n",
    "After training the model for 50 epoch, the validation loss stopped increasing and we stopped trainig the model. The accuracy on the test set was 54%. \n",
    "This is very inferior to all the other methods we have tried so far, that were performed after extracting a set of 2048 important features thanks to a pretrained model. \n",
    "\n",
    "This can be explained by the fact that our CNN is way more simpler than the inception_v3 CNN, as well as by the fact that our CNN was trained on a much smaller dataset. \n",
    "\n",
    "Finally, we save the our result in order to do a final comparison of all the methods we have implemented so far. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f97bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('results/09_CNN.npz', test_accuracy=test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
